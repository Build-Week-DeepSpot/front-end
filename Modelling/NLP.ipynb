{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "413_follow_along.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.0 64-bit ('U4-S2-NN': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "02e1903c3f39b96bcefa6d49f9b3f85f880bb59f74a50c875b853cacbce3839e"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "# from joblib import dump, load\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# Load data\n",
        "file = '../../data/spotify_songs.csv'\n",
        "df = pd.read_csv(file)\n",
        "df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18454, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# Get only English songs\n",
        "songs = df[df.language == 'en']\n",
        "songs.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15405, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# Check for null values\n",
        "songs.isnull().sum().sum() == 0"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "def clean_data(data):\n",
        "    # Remove non-alphanumeric characters\n",
        "    data = data.apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
        "\n",
        "    # Remove extra whitespace and lowercase text \n",
        "    data = data.apply(lambda x: ' '.join(x.lower().split()))\n",
        "\n",
        "    # Remove short words\n",
        "    data = data.apply(lambda x: ' '.join(x for x in x.split() if len(x) > 2))\n",
        "    \n",
        "    # Stop words will be removed in vectorizer\n",
        "    return data"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# Add cleaned lyrics to df\n",
        "songs['clean_lyrics'] = clean_data(songs['lyrics'])\n",
        "songs.clean_lyrics.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/Carl/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    the trees are singing the wind the sky blue on...\n",
              "2    yeah spyderman and freeze full effect huh you ...\n",
              "3    really can stay baby cold outside got away bab...\n",
              "4    get out business you don keep from turning wit...\n",
              "5    hold your breath don look down keep trying dar...\n",
              "Name: clean_lyrics, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# Tokenizer function\n",
        "def tokenizer(song):\n",
        "    # Create a list of tokens\n",
        "    tokens = []\n",
        "    # Split song into words\n",
        "    words = song.split()\n",
        "    # Iterate through the words in the song\n",
        "    for word in words:\n",
        "        tokens.append(word)\n",
        "          \n",
        "    return tokens"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# Tokenize clean lyrics\n",
        "songs['tokens'] = songs.clean_lyrics.apply(tokenizer)\n",
        "songs['tokens'].head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/Carl/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    [the, trees, are, singing, the, wind, the, sky...\n",
              "2    [yeah, spyderman, and, freeze, full, effect, h...\n",
              "3    [really, can, stay, baby, cold, outside, got, ...\n",
              "4    [get, out, business, you, don, keep, from, tur...\n",
              "5    [hold, your, breath, don, look, down, keep, tr...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "def count(tokens):\n",
        "    \"\"\"\n",
        "    Calculates some basic statistics about tokens in our corpus (i.e. corpus means collections text data)\n",
        "    \"\"\"\n",
        "    # stores the count of each token\n",
        "    word_counts = Counter()\n",
        "    \n",
        "    # stores the number of docs that each token appears in \n",
        "    appears_in = Counter()\n",
        "\n",
        "    total_docs = len(tokens)\n",
        "\n",
        "    for token in tokens:\n",
        "        # stores count of every appearance of a token \n",
        "        word_counts.update(token)\n",
        "        # use set() in order to not count duplicates, thereby count the num of docs that each token appears in\n",
        "        appears_in.update(set(token))\n",
        "\n",
        "    # build word count dataframe\n",
        "    temp = zip(word_counts.keys(), word_counts.values())\n",
        "    wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
        "\n",
        "    # rank the the word counts\n",
        "    wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
        "    total = wc['count'].sum()\n",
        "\n",
        "    # calculate the percent total of each token\n",
        "    wc['pct_total'] = wc['count'].apply(lambda token_count: token_count / total)\n",
        "\n",
        "    # calculate the cumulative percent total of word counts \n",
        "    wc = wc.sort_values(by='rank')\n",
        "    wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
        "\n",
        "    # create dataframe for document stats\n",
        "    t2 = zip(appears_in.keys(), appears_in.values())\n",
        "    ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
        "    \n",
        "    # merge word count stats with doc stats\n",
        "    wc = ac.merge(wc, on='word')\n",
        "\n",
        "    wc['appears_in_pct'] = wc['appears_in'].apply(lambda x: x / total_docs)\n",
        "\n",
        "    return wc.sort_values(by='rank')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "wc  = count(songs['tokens'])\n",
        "wc.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    word  appears_in   count  rank  pct_total  cul_pct_total  appears_in_pct\n",
              "43   you       14166  278601   1.0   0.057869       0.057869        0.919572\n",
              "45   the       14535  222028   2.0   0.046118       0.103988        0.943525\n",
              "48   and       13634  119728   3.0   0.024869       0.128857        0.885037\n",
              "3   that       11362   73654   4.0   0.015299       0.144156        0.737553\n",
              "7   your       10233   58122   5.0   0.012073       0.156229        0.664265"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>appears_in</th>\n",
              "      <th>count</th>\n",
              "      <th>rank</th>\n",
              "      <th>pct_total</th>\n",
              "      <th>cul_pct_total</th>\n",
              "      <th>appears_in_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>you</td>\n",
              "      <td>14166</td>\n",
              "      <td>278601</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.057869</td>\n",
              "      <td>0.057869</td>\n",
              "      <td>0.919572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>the</td>\n",
              "      <td>14535</td>\n",
              "      <td>222028</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.046118</td>\n",
              "      <td>0.103988</td>\n",
              "      <td>0.943525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>and</td>\n",
              "      <td>13634</td>\n",
              "      <td>119728</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.024869</td>\n",
              "      <td>0.128857</td>\n",
              "      <td>0.885037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>that</td>\n",
              "      <td>11362</td>\n",
              "      <td>73654</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.015299</td>\n",
              "      <td>0.144156</td>\n",
              "      <td>0.737553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>your</td>\n",
              "      <td>10233</td>\n",
              "      <td>58122</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.012073</td>\n",
              "      <td>0.156229</td>\n",
              "      <td>0.664265</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "len(wc)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43107"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "# TFIDF vectorizer\n",
        "tfidf = TfidfVectorizer(\n",
        "    stop_words='english', ngram_range=(1,2),\n",
        "    min_df=5, max_df=0.2,\n",
        "    max_features=500,\n",
        "    tokenizer=tokenizer)\n",
        "\n",
        "# Create a vocabulary and get word counts per document\n",
        "dtm = tfidf.fit_transform(songs.clean_lyrics)\n",
        "dtm = pd.DataFrame(data=dtm.toarray(), columns=tfidf.get_feature_names())\n",
        "print(dtm.shape)\n",
        "dtm.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15405, 500)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   act  afraid  ahh  ain got  air     alive  alright  anymore  apart  arms  \\\n",
              "0  0.0     0.0  0.0      0.0  0.0  0.424324      0.0      0.0    0.0   0.0   \n",
              "1  0.0     0.0  0.0      0.0  0.0  0.000000      0.0      0.0    0.0   0.0   \n",
              "2  0.0     0.0  0.0      0.0  0.0  0.000000      0.0      0.0    0.0   0.0   \n",
              "3  0.0     0.0  0.0      0.0  0.0  0.000000      0.0      0.0    0.0   0.0   \n",
              "4  0.0     0.0  0.0      0.0  0.0  0.000000      0.0      0.0    0.0   0.0   \n",
              "\n",
              "   ...     worth  wouldn     wrong  yeah don  yeah got  yeah know  yeah yeah  \\\n",
              "0  ...  0.000000     0.0  0.000000       0.0       0.0   0.000000   0.000000   \n",
              "1  ...  0.000000     0.0  0.156461       0.0       0.0   0.000000   0.000000   \n",
              "2  ...  0.000000     0.0  0.000000       0.0       0.0   0.000000   0.000000   \n",
              "3  ...  0.000000     0.0  0.000000       0.0       0.0   0.000000   0.000000   \n",
              "4  ...  0.352606     0.0  0.000000       0.0       0.0   0.114416   0.245309   \n",
              "\n",
              "   years  yes  young  \n",
              "0    0.0  0.0    0.0  \n",
              "1    0.0  0.0    0.0  \n",
              "2    0.0  0.0    0.0  \n",
              "3    0.0  0.0    0.0  \n",
              "4    0.0  0.0    0.0  \n",
              "\n",
              "[5 rows x 500 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>act</th>\n",
              "      <th>afraid</th>\n",
              "      <th>ahh</th>\n",
              "      <th>ain got</th>\n",
              "      <th>air</th>\n",
              "      <th>alive</th>\n",
              "      <th>alright</th>\n",
              "      <th>anymore</th>\n",
              "      <th>apart</th>\n",
              "      <th>arms</th>\n",
              "      <th>...</th>\n",
              "      <th>worth</th>\n",
              "      <th>wouldn</th>\n",
              "      <th>wrong</th>\n",
              "      <th>yeah don</th>\n",
              "      <th>yeah got</th>\n",
              "      <th>yeah know</th>\n",
              "      <th>yeah yeah</th>\n",
              "      <th>years</th>\n",
              "      <th>yes</th>\n",
              "      <th>young</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.424324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.156461</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.352606</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.114416</td>\n",
              "      <td>0.245309</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 500 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "# Nearest neighbors model \n",
        "nn = NearestNeighbors(n_neighbors=6, algorithm=\"kd_tree\")\n",
        "\n",
        "# Fit on DTM\n",
        "nn.fit(dtm)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree', n_neighbors=6)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "source": [
        "# sample a doc from dtm to use as our query point \n",
        "n = 12320\n",
        "doc_vector = [dtm.iloc[n]]\n",
        "\n",
        "# Query Using kneighbors \n",
        "neigh_dist, neigh_ind = nn.kneighbors(doc_vector)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "source": [
        "# Display test song and nearest neighbors\n",
        "print('Test song:', songs.iloc[n]['track_name'])\n",
        "print(f'https://open.spotify.com/track/{songs.iloc[n].track_id}')\n",
        "print(songs.iloc[n]['lyrics'])\n",
        "print('\\nPredictions:')\n",
        "\n",
        "for i in range(6):\n",
        "    ind = neigh_ind[0][i]\n",
        "    if ind != n:\n",
        "        track_name = songs.iloc[ind]['track_name']\n",
        "        artist = songs.iloc[ind]['track_artist']\n",
        "        lyrics = songs.iloc[ind]['lyrics']\n",
        "        print(f'{track_name} by {artist}')\n",
        "        print(f'https://open.spotify.com/track/{songs.iloc[ind].track_id}')\n",
        "        print(lyrics, '\\n')\n",
        "    # print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test song: Bad Bad News\n",
            "https://open.spotify.com/track/5CDrDzan4wRW3Dj4LD6meH\n",
            "Ain't got no riches, ain't got no money that runs long But I got a heart that's strong and a love that's tall Ain't got no name, ain't got no fancy education But I can see right through, a powdered face on a painted fool Let me slip through (Let me slip through) Why you tryna hold me back? (I ain't) I'm just tryna move up front Lil more of this, lil less of that (Can you feel me?) Let me come through (Let me come through) I'm tired being in the back (Aight) I'm just tryna move up front A lil more of this, a lil less of that, yeah They tell me I was born to lose But I made a good good thing out of bad bad news I don't worry, don't worry, don't worry about people in my face I hit ‘em with the style and grace, and watch their ankles break I know you wish, I know you wish I would fade away But I got more to say, Lord they pray Let me slip through (Let me slip through) Why you tryna hold me back? (I ain't) I'm just tryna move up front Lil more of this, lil less of that (Can you feel me?) Let me come through (Let me come through) I'm tired being in the back (Aight) I'm just trynna move up front A lil more of this, a lil less of that, yeah They tell me I was born to lose But I made a good good thing out of bad bad news Alright alright, all day all night Alright alright, all day all night Alright alright, all day all night Alright alright, all day all night They tell me I was born to lose But I made a good good thing out of bad bad news\n",
            "\n",
            "Predictions:\n",
            "Bad Bad News by Leon Bridges\n",
            "https://open.spotify.com/track/7FxzgizJRGTQ3fxUqfvljg\n",
            "Ain't got no riches, ain't got no money that runs long But I got a heart that's strong and a love that's tall Ain't got no name, ain't got no fancy education But I can see right through, a powdered face on a painted fool Let me slip through (Let me slip through) Why you tryna hold me back? (I ain't) I'm just tryna move up front Lil more of this, lil less of that (Can you feel me?) Let me come through (Let me come through) I'm tired being in the back (Aight) I'm just tryna move up front A lil more of this, a lil less of that, yeah They tell me I was born to lose But I made a good good thing out of bad bad news I don't worry, don't worry, don't worry about people in my face I hit ‘em with the style and grace, and watch their ankles break I know you wish, I know you wish I would fade away But I got more to say, Lord they pray Let me slip through (Let me slip through) Why you tryna hold me back? (I ain't) I'm just tryna move up front Lil more of this, lil less of that (Can you feel me?) Let me come through (Let me come through) I'm tired being in the back (Aight) I'm just trynna move up front A lil more of this, a lil less of that, yeah They tell me I was born to lose But I made a good good thing out of bad bad news Alright alright, all day all night Alright alright, all day all night Alright alright, all day all night Alright alright, all day all night They tell me I was born to lose But I made a good good thing out of bad bad news \n",
            "\n",
            "Sunset Lover by Petit Biscuit\n",
            "https://open.spotify.com/track/0hNduWmlWmEmuwEFcYvRu1\n",
            "Hallelujah, oh, I'm down on the beach Hallelujah, oh, I'm down on the beach \n",
            "\n",
            "Booty Loose (feat. Fly Boi Keno) by Party Favor\n",
            "https://open.spotify.com/track/06vSnlO8lrC5o69qz9fW9f\n",
            "Bend and make your booty loose, that booty loose Bend and make your booty loose, that booty loose Bend and make your booty loose, that booty loose Bend and make your booty loose, that booty loose Bend and make your booty loose, show me what this booty do Show me what this booty do Get loose with it Get loose with it You're too smooth with it You're to smooth with it Get loose with it Get loose with it You're too smooth with it You're too smooth with it Bend and make your booty loose, that booty loose Bend and make your booty loose, that booty loose Bend and make your booty loose, that booty loose Bend and make your booty loose, that booty loose Get loose with it Get loose, loose  with it, with it Get loose with it Get loose,loose with it, with it Get loose with it Get loose,loose with it,with it Get loose with it Show me what this booty do Get loose with it Get loose with it You're too smooth with it You're too smooth with it Get loose with it Get loose with it You're too smooth with it You're too smooth with it Get loose with it Get loose with it You're too smooth with it You're too smooth with it Get loose with it Get loose with it You're too smooth with it You're too smooth with it \n",
            "\n",
            "Beast by PURARI\n",
            "https://open.spotify.com/track/0bqz8PQRyKw8Uwi02NsV3q\n",
            "You have five seconds to terminate this tape Five Four Three Two One \n",
            "\n",
            "Paris by Kungs\n",
            "https://open.spotify.com/track/0k4A0wcdZLY0OSQ1ugfi3J\n",
            "Don't Lyrics \n",
            "\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "dtm.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15405, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "# Autoencoder\n",
        "\n",
        "encoded_dim = 32\n",
        "layer_1 = 64\n",
        "layer_2 = 128\n",
        "\n",
        "input_doc = Input(shape = (dtm.shape[1], ))\n",
        "\n",
        "x = Dense(layer_1, activation = 'relu')(input_doc)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(layer_2, activation = 'relu')(x)\n",
        "encoded = Dense(encoded_dim, activation = 'relu')(x)\n",
        "x = Dense(layer_2, activation='sigmoid')(encoded)\n",
        "x = Dense(layer_1, activation = 'relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "decoded = Dense(dtm.shape[1], activation='sigmoid')(x)\n",
        "\n",
        "autoencoder = Model(input_doc, decoded)\n",
        "\n",
        "encoder = Model(input_doc, encoded)\n",
        "\n",
        "autoencoder.compile(optimizer='nadam', loss='mean_squared_error', metrics=['accuracy'])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "autoencoder.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1000)]            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                64064     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               4224      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1000)              65000     \n",
            "=================================================================\n",
            "Total params: 153,992\n",
            "Trainable params: 153,992\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3)\n",
        "\n",
        "autoencoder.fit(dtm, # input image to encoder\n",
        "                dtm, # provide input image to decoder so the model learns how to reconstruct the input image \n",
        "                batch_size=32,\n",
        "                epochs=100,\n",
        "                validation_split=.2,\n",
        "                callbacks=[stop])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
            "Train on 12324 samples, validate on 3081 samples\n",
            "Epoch 1/100\n",
            "12324/12324 [==============================] - 6s 485us/sample - loss: 0.0118 - accuracy: 0.0015 - val_loss: 9.8527e-04 - val_accuracy: 0.0081\n",
            "Epoch 2/100\n",
            "12324/12324 [==============================] - 5s 414us/sample - loss: 0.0010 - accuracy: 0.0030 - val_loss: 9.8685e-04 - val_accuracy: 0.0075\n",
            "Epoch 3/100\n",
            "12324/12324 [==============================] - 5s 413us/sample - loss: 9.9584e-04 - accuracy: 0.0035 - val_loss: 9.8698e-04 - val_accuracy: 0.0039\n",
            "Epoch 4/100\n",
            "12324/12324 [==============================] - 5s 408us/sample - loss: 9.9302e-04 - accuracy: 0.0047 - val_loss: 9.8650e-04 - val_accuracy: 0.0039\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff8d79a07b8>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ]
}