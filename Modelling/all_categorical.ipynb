{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# from ipynb.fs.full.Preprocessing import clean_data\n",
    "%load_ext tensorboard"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Tracks file with ids, titles, names, etc.\n",
    "tracks = pd.read_csv('../../data/tracks.csv')\n",
    "print(tracks.shape)\n",
    "# tracks.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(586672, 20)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# New cleaned songs file with all features as one-hot categorical variables \n",
    "df = pd.read_csv('../../data/new_songs_cleaned.csv', index_col='Unnamed: 0')\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(586344, 74)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   popularity_1  popularity_2  popularity_3  popularity_4  popularity_5  \\\n",
       "0             1             0             0             0             0   \n",
       "1             1             0             0             0             0   \n",
       "2             1             0             0             0             0   \n",
       "3             1             0             0             0             0   \n",
       "4             1             0             0             0             0   \n",
       "\n",
       "   duration_ms_1  duration_ms_2  duration_ms_3  duration_ms_4  duration_ms_5  \\\n",
       "0              1              0              0              0              0   \n",
       "1              1              0              0              0              0   \n",
       "2              1              0              0              0              0   \n",
       "3              1              0              0              0              0   \n",
       "4              1              0              0              0              0   \n",
       "\n",
       "   ...  valence_5  tempo_1  tempo_2  tempo_3  tempo_4  tempo_5  \\\n",
       "0  ...          0        1        0        0        0        0   \n",
       "1  ...          0        1        0        0        0        0   \n",
       "2  ...          0        0        1        0        0        0   \n",
       "3  ...          0        0        0        1        0        0   \n",
       "4  ...          0        1        0        0        0        0   \n",
       "\n",
       "   time_signature_1  time_signature_2  time_signature_3  time_signature_4  \n",
       "0                 1                 0                 0                 0  \n",
       "1                 0                 1                 0                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 1                 0                 0                 0  \n",
       "4                 0                 0                 0                 1  \n",
       "\n",
       "[5 rows x 74 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity_1</th>\n",
       "      <th>popularity_2</th>\n",
       "      <th>popularity_3</th>\n",
       "      <th>popularity_4</th>\n",
       "      <th>popularity_5</th>\n",
       "      <th>duration_ms_1</th>\n",
       "      <th>duration_ms_2</th>\n",
       "      <th>duration_ms_3</th>\n",
       "      <th>duration_ms_4</th>\n",
       "      <th>duration_ms_5</th>\n",
       "      <th>...</th>\n",
       "      <th>valence_5</th>\n",
       "      <th>tempo_1</th>\n",
       "      <th>tempo_2</th>\n",
       "      <th>tempo_3</th>\n",
       "      <th>tempo_4</th>\n",
       "      <th>tempo_5</th>\n",
       "      <th>time_signature_1</th>\n",
       "      <th>time_signature_2</th>\n",
       "      <th>time_signature_3</th>\n",
       "      <th>time_signature_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Smaller dataframe for rapid testing\n",
    "\n",
    "# small_new_df = new_df.iloc[:150000]\n",
    "# print(small_new_df.shape)\n",
    "# small_new_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Autoencoder using new_songs_cleaned (all categorical) VAL_LOSS = 0.0015\n",
    "data = df\n",
    "\n",
    "encoded_dim = 16\n",
    "\n",
    "input_song = Input(shape = (data.shape[1], ))\n",
    "h1 = Dense(32, activation = 'relu')(input_song)\n",
    "encoded = Dense(encoded_dim, activation = 'relu')(h1)\n",
    "\n",
    "dh1 = Dense(32, activation='sigmoid')(encoded)\n",
    "decoded = Dense(data.shape[1], activation='sigmoid')(dh1)\n",
    "\n",
    "autoencoder = Model(input_song, decoded)\n",
    "encoder = Model(input_song, encoded)\n",
    "\n",
    "opt = tf.keras.optimizers.Nadam()\n",
    "autoencoder.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3, restore_best_weights=True)\n",
    "\n",
    "autoencoder.fit(data, # input image to encoder\n",
    "                data, # provide input image to decoder so the model learns how to reconstruct the input image \n",
    "                batch_size=32,\n",
    "                epochs=100,\n",
    "                validation_split=.2,\n",
    "                callbacks=[stop])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 469075 samples, validate on 117269 samples\n",
      "Epoch 1/100\n",
      "469075/469075 [==============================] - 28s 61us/sample - loss: 0.0412 - accuracy: 0.0038 - val_loss: 0.0264 - val_accuracy: 0.0043\n",
      "Epoch 2/100\n",
      "469075/469075 [==============================] - 28s 59us/sample - loss: 0.0224 - accuracy: 0.0046 - val_loss: 0.0203 - val_accuracy: 0.0070\n",
      "Epoch 3/100\n",
      "469075/469075 [==============================] - 27s 58us/sample - loss: 0.0177 - accuracy: 0.0017 - val_loss: 0.0170 - val_accuracy: 4.9459e-04\n",
      "Epoch 4/100\n",
      "469075/469075 [==============================] - 29s 61us/sample - loss: 0.0147 - accuracy: 3.5815e-04 - val_loss: 0.0149 - val_accuracy: 1.4497e-04\n",
      "Epoch 5/100\n",
      "469075/469075 [==============================] - 27s 57us/sample - loss: 0.0128 - accuracy: 1.3644e-04 - val_loss: 0.0132 - val_accuracy: 1.1086e-04\n",
      "Epoch 6/100\n",
      "469075/469075 [==============================] - 27s 58us/sample - loss: 0.0109 - accuracy: 1.2791e-05 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "469075/469075 [==============================] - 27s 58us/sample - loss: 0.0096 - accuracy: 2.1319e-06 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "469075/469075 [==============================] - 28s 59us/sample - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 8.5274e-06\n",
      "Epoch 9/100\n",
      "468672/469075 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 6.4011e-06"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get song encodings\n",
    "data = df\n",
    "decoded_songs = autoencoder.predict(data)\n",
    "encoded_songs = encoder.predict(data)\n",
    "\n",
    "embeddings_df = pd.DataFrame(encoded_songs, index=data.index)\n",
    "print(embeddings_df.shape)\n",
    "embeddings_df.head(3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def find_neighbors(song):\n",
    "    '''\n",
    "    Find the nearest neighbors of a song\n",
    "    1. Checks for song\n",
    "    2. Loads and process the embeddings into an array\n",
    "    3. Trains a nearest neighbors model\n",
    "    4. Finds the 10 nearest neighbors of the given song\n",
    "    ARGUMENTS: song in string form\n",
    "    RETURNS: index of test song, list of prediction indices\n",
    "    '''\n",
    "    # 1. Check if song exists: if yes, use first result\n",
    "    songs = tracks.index[tracks.name == song] \n",
    "    if len(songs) <1:\n",
    "        return 'ERROR: Not a valid song name' \n",
    "    else:\n",
    "        song_index = songs[0]\n",
    "\n",
    "    # 2. Load data ---> ALREADY DONE\n",
    "    # file = 'embeddings_df_001.csv' # USE CORRECT PATH\n",
    "    # embeddings = pd.read_csv(file)\n",
    "    # # Drop extra index column\n",
    "    # embeddings.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    # # Convert dataframe to numpy array\n",
    "    # encoded_songs = embeddings.to_numpy()\n",
    "\n",
    "    # 3. Train nearest neighbors model on encodings\n",
    "    nn = NearestNeighbors(n_neighbors=11, algorithm='ball_tree')\n",
    "    nn.fit(encoded_songs)\n",
    "\n",
    "    # 4. Get neigbors of song\n",
    "    test_encoding = encoded_songs[song_index].reshape(1,-1)\n",
    "    _, n_indices = nn.kneighbors(test_encoding)\n",
    "    # First result is often the song, so leave out\n",
    "    n_indices = n_indices.tolist()[0][1:] \n",
    "\n",
    "    return song_index, n_indices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Song to search by\n",
    "song = 'Yellow Submarine'\n",
    "\n",
    "# Find neighbors\n",
    "test_song, neighbors = find_neighbors(song)\n",
    "\n",
    "# Display test song and nearest neighbors\n",
    "# First display song from search query\n",
    "ind = test_song\n",
    "name = tracks.iloc[ind]['name']\n",
    "artist = tracks.iloc[ind]['artists']\n",
    "print(f'Test song: {name} by {artist}')\n",
    "print(f'https://open.spotify.com/track/{tracks.iloc[ind].id}')\n",
    "# Next display predicitons\n",
    "print('\\nPredictions:')\n",
    "for i in range(10):\n",
    "    ind = neighbors[i]\n",
    "    name = tracks.iloc[ind]['name']\n",
    "    artist = tracks.iloc[ind]['artists']\n",
    "    print(f'{name} by {artist}')\n",
    "    print(f'   https://open.spotify.com/track/{tracks.iloc[ind].id}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('U4-S2-NN': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "interpreter": {
   "hash": "02e1903c3f39b96bcefa6d49f9b3f85f880bb59f74a50c875b853cacbce3839e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}