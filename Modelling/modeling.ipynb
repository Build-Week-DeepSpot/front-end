{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old df shape: (586672, 20)\n",
      "Old df columns: ['id', 'name', 'popularity', 'duration_ms', 'explicit', 'artists', 'id_artists', 'release_date', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']\n",
      "\n",
      "Cleaned df shape: (586344, 26)\n",
      "Clean df columns: ['popularity', 'duration_ms', 'explicit', 'danceability', 'energy', 'key_1', 'key_2', 'key_3', 'key_4', 'key_5', 'key_6', 'key_7', 'key_8', 'key_9', 'key_10', 'key_11', 'key_12', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']\n",
      "(586344, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>...</th>\n",
       "      <th>key_12</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.863440e+05</td>\n",
       "      <td>5.863440e+05</td>\n",
       "      <td>5.863440e+05</td>\n",
       "      <td>5.863440e+05</td>\n",
       "      <td>5.863440e+05</td>\n",
       "      <td>586344.000000</td>\n",
       "      <td>586344.000000</td>\n",
       "      <td>586344.000000</td>\n",
       "      <td>586344.000000</td>\n",
       "      <td>586344.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>586344.000000</td>\n",
       "      <td>5.863440e+05</td>\n",
       "      <td>586344.000000</td>\n",
       "      <td>5.863440e+05</td>\n",
       "      <td>5.863440e+05</td>\n",
       "      <td>5.863440e+05</td>\n",
       "      <td>5.863440e+05</td>\n",
       "      <td>5.863440e+05</td>\n",
       "      <td>5.863440e+05</td>\n",
       "      <td>5.863440e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-6.541704e-14</td>\n",
       "      <td>4.196940e-16</td>\n",
       "      <td>-1.393941e-13</td>\n",
       "      <td>-5.074522e-15</td>\n",
       "      <td>-2.380274e-15</td>\n",
       "      <td>0.127717</td>\n",
       "      <td>0.071086</td>\n",
       "      <td>0.125781</td>\n",
       "      <td>0.036711</td>\n",
       "      <td>0.091388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111044</td>\n",
       "      <td>2.978384e-16</td>\n",
       "      <td>0.658792</td>\n",
       "      <td>-2.960057e-15</td>\n",
       "      <td>-1.125049e-14</td>\n",
       "      <td>-4.119535e-14</td>\n",
       "      <td>8.449369e-17</td>\n",
       "      <td>-1.382204e-16</td>\n",
       "      <td>7.580292e-16</td>\n",
       "      <td>9.434782e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.998227e-01</td>\n",
       "      <td>9.952174e-01</td>\n",
       "      <td>1.000212e+00</td>\n",
       "      <td>9.970543e-01</td>\n",
       "      <td>9.994280e-01</td>\n",
       "      <td>0.333775</td>\n",
       "      <td>0.256969</td>\n",
       "      <td>0.331603</td>\n",
       "      <td>0.188050</td>\n",
       "      <td>0.288161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314187</td>\n",
       "      <td>9.963881e-01</td>\n",
       "      <td>0.474115</td>\n",
       "      <td>1.000185e+00</td>\n",
       "      <td>9.998803e-01</td>\n",
       "      <td>9.992351e-01</td>\n",
       "      <td>9.996187e-01</td>\n",
       "      <td>9.989943e-01</td>\n",
       "      <td>9.958386e-01</td>\n",
       "      <td>9.813526e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.500701e+00</td>\n",
       "      <td>-1.697285e+00</td>\n",
       "      <td>-2.148490e-01</td>\n",
       "      <td>-3.074662e+00</td>\n",
       "      <td>-2.152405e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.802915e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.832490e-01</td>\n",
       "      <td>-1.289455e+00</td>\n",
       "      <td>-4.244867e-01</td>\n",
       "      <td>-1.129392e+00</td>\n",
       "      <td>-2.144603e+00</td>\n",
       "      <td>-2.957428e+00</td>\n",
       "      <td>-8.190745e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.930492e-01</td>\n",
       "      <td>-4.340974e-01</td>\n",
       "      <td>-2.148490e-01</td>\n",
       "      <td>-6.677147e-01</td>\n",
       "      <td>-7.869069e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.279452e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.942474e-01</td>\n",
       "      <td>-1.011674e+00</td>\n",
       "      <td>-4.244867e-01</td>\n",
       "      <td>-6.271283e-01</td>\n",
       "      <td>-8.018040e-01</td>\n",
       "      <td>-7.687832e-01</td>\n",
       "      <td>2.630195e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.096308e-02</td>\n",
       "      <td>-1.195375e-01</td>\n",
       "      <td>-2.148490e-01</td>\n",
       "      <td>7.881222e-02</td>\n",
       "      <td>2.683466e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.884565e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.369910e-01</td>\n",
       "      <td>-7.971846e-02</td>\n",
       "      <td>-4.243953e-01</td>\n",
       "      <td>-4.063232e-01</td>\n",
       "      <td>4.423698e-02</td>\n",
       "      <td>-3.746548e-02</td>\n",
       "      <td>2.630195e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.311231e-01</td>\n",
       "      <td>2.673159e-01</td>\n",
       "      <td>-2.148490e-01</td>\n",
       "      <td>7.350335e-01</td>\n",
       "      <td>8.167594e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.307683e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.585512e-01</td>\n",
       "      <td>9.580173e-01</td>\n",
       "      <td>-3.888886e-01</td>\n",
       "      <td>3.477778e-01</td>\n",
       "      <td>8.398260e-01</td>\n",
       "      <td>5.982336e-01</td>\n",
       "      <td>2.630195e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.942772e+00</td>\n",
       "      <td>4.260912e+01</td>\n",
       "      <td>4.656401e+00</td>\n",
       "      <td>2.571249e+00</td>\n",
       "      <td>1.817066e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.060351e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.814415e+00</td>\n",
       "      <td>1.565752e+00</td>\n",
       "      <td>3.322689e+00</td>\n",
       "      <td>4.264763e+00</td>\n",
       "      <td>1.736319e+00</td>\n",
       "      <td>4.295441e+00</td>\n",
       "      <td>2.376461e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         popularity   duration_ms      explicit  danceability        energy  \\\n",
       "count  5.863440e+05  5.863440e+05  5.863440e+05  5.863440e+05  5.863440e+05   \n",
       "mean  -6.541704e-14  4.196940e-16 -1.393941e-13 -5.074522e-15 -2.380274e-15   \n",
       "std    9.998227e-01  9.952174e-01  1.000212e+00  9.970543e-01  9.994280e-01   \n",
       "min   -1.500701e+00 -1.697285e+00 -2.148490e-01 -3.074662e+00 -2.152405e+00   \n",
       "25%   -7.930492e-01 -4.340974e-01 -2.148490e-01 -6.677147e-01 -7.869069e-01   \n",
       "50%   -3.096308e-02 -1.195375e-01 -2.148490e-01  7.881222e-02  2.683466e-02   \n",
       "75%    7.311231e-01  2.673159e-01 -2.148490e-01  7.350335e-01  8.167594e-01   \n",
       "max    3.942772e+00  4.260912e+01  4.656401e+00  2.571249e+00  1.817066e+00   \n",
       "\n",
       "               key_1          key_2          key_3          key_4  \\\n",
       "count  586344.000000  586344.000000  586344.000000  586344.000000   \n",
       "mean        0.127717       0.071086       0.125781       0.036711   \n",
       "std         0.333775       0.256969       0.331603       0.188050   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "               key_5  ...         key_12      loudness           mode  \\\n",
       "count  586344.000000  ...  586344.000000  5.863440e+05  586344.000000   \n",
       "mean        0.091388  ...       0.111044  2.978384e-16       0.658792   \n",
       "std         0.288161  ...       0.314187  9.963881e-01       0.474115   \n",
       "min         0.000000  ...       0.000000 -8.802915e+00       0.000000   \n",
       "25%         0.000000  ...       0.000000 -5.279452e-01       0.000000   \n",
       "50%         0.000000  ...       0.000000  1.884565e-01       1.000000   \n",
       "75%         0.000000  ...       0.000000  7.307683e-01       1.000000   \n",
       "max         1.000000  ...       1.000000  3.060351e+00       1.000000   \n",
       "\n",
       "        speechiness  acousticness  instrumentalness      liveness  \\\n",
       "count  5.863440e+05  5.863440e+05      5.863440e+05  5.863440e+05   \n",
       "mean  -2.960057e-15 -1.125049e-14     -4.119535e-14  8.449369e-17   \n",
       "std    1.000185e+00  9.998803e-01      9.992351e-01  9.996187e-01   \n",
       "min   -5.832490e-01 -1.289455e+00     -4.244867e-01 -1.129392e+00   \n",
       "25%   -3.942474e-01 -1.011674e+00     -4.244867e-01 -6.271283e-01   \n",
       "50%   -3.369910e-01 -7.971846e-02     -4.243953e-01 -4.063232e-01   \n",
       "75%   -1.585512e-01  9.580173e-01     -3.888886e-01  3.477778e-01   \n",
       "max    4.814415e+00  1.565752e+00      3.322689e+00  4.264763e+00   \n",
       "\n",
       "            valence         tempo  time_signature  \n",
       "count  5.863440e+05  5.863440e+05    5.863440e+05  \n",
       "mean  -1.382204e-16  7.580292e-16    9.434782e-14  \n",
       "std    9.989943e-01  9.958386e-01    9.813526e-01  \n",
       "min   -2.144603e+00 -2.957428e+00   -8.190745e+00  \n",
       "25%   -8.018040e-01 -7.687832e-01    2.630195e-01  \n",
       "50%    4.423698e-02 -3.746548e-02    2.630195e-01  \n",
       "75%    8.398260e-01  5.982336e-01    2.630195e-01  \n",
       "max    1.736319e+00  4.295441e+00    2.376461e+00  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from ipynb.fs.full.Preprocessing import clean_data\n",
    "%load_ext tensorboard\n",
    "\n",
    "df = pd.read_csv('./Data/songs_cleaned.csv', index_col='Unnamed: 0')\n",
    "print(df.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 11:28:26.904560: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Simple autoencoder\n",
    "\n",
    "encoded_dim = 16\n",
    "\n",
    "input_song = Input(shape = (df.shape[1], ))\n",
    "\n",
    "h1 = Dense(32, activation = 'relu')(input_song)\n",
    "\n",
    "encoded = Dense(encoded_dim, activation = 'relu')(h1)\n",
    "\n",
    "dh1 = Dense(32, activation='sigmoid')(encoded)\n",
    "\n",
    "decoded = Dense(df.shape[1], activation='sigmoid')(dh1)\n",
    "\n",
    "autoencoder = Model(input_song, decoded)\n",
    "\n",
    "encoder = Model(input_song, encoded)\n",
    "\n",
    "autoencoder.compile(optimizer='nadam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 11:28:27.000896: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-08-20 11:28:27.000922: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-08-20 11:28:27.002211: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-08-20 11:28:27.501421: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  146/14659 [..............................] - ETA: 17s - loss: 0.6089 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 11:28:28.438792: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-08-20 11:28:28.438809: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-08-20 11:28:28.443691: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-08-20 11:28:28.460467: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-08-20 11:28:28.474874: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/SimpleAutoencoder-20210820-112826/train/plugins/profile/2021_08_20_11_28_28\n",
      "2021-08-20 11:28:28.476965: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to logs/SimpleAutoencoder-20210820-112826/train/plugins/profile/2021_08_20_11_28_28/Petrs-MBP.trace.json.gz\n",
      "2021-08-20 11:28:28.490467: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/SimpleAutoencoder-20210820-112826/train/plugins/profile/2021_08_20_11_28_28\n",
      "2021-08-20 11:28:28.490765: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to logs/SimpleAutoencoder-20210820-112826/train/plugins/profile/2021_08_20_11_28_28/Petrs-MBP.memory_profile.json.gz\n",
      "2021-08-20 11:28:28.492157: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/SimpleAutoencoder-20210820-112826/train/plugins/profile/2021_08_20_11_28_28Dumped tool data for xplane.pb to logs/SimpleAutoencoder-20210820-112826/train/plugins/profile/2021_08_20_11_28_28/Petrs-MBP.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/SimpleAutoencoder-20210820-112826/train/plugins/profile/2021_08_20_11_28_28/Petrs-MBP.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/SimpleAutoencoder-20210820-112826/train/plugins/profile/2021_08_20_11_28_28/Petrs-MBP.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/SimpleAutoencoder-20210820-112826/train/plugins/profile/2021_08_20_11_28_28/Petrs-MBP.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/SimpleAutoencoder-20210820-112826/train/plugins/profile/2021_08_20_11_28_28/Petrs-MBP.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14659/14659 [==============================] - 11s 728us/step - loss: 0.3364 - val_loss: 0.3274\n",
      "Epoch 2/100\n",
      "14659/14659 [==============================] - 11s 727us/step - loss: 0.2994 - val_loss: 0.3214\n",
      "Epoch 3/100\n",
      "14659/14659 [==============================] - 11s 721us/step - loss: 0.2972 - val_loss: 0.3202\n",
      "Epoch 4/100\n",
      "14659/14659 [==============================] - 10s 707us/step - loss: 0.2965 - val_loss: 0.3197\n",
      "Epoch 5/100\n",
      "14659/14659 [==============================] - 10s 711us/step - loss: 0.2957 - val_loss: 0.3180\n",
      "Epoch 6/100\n",
      "14659/14659 [==============================] - 11s 774us/step - loss: 0.2949 - val_loss: 0.3172\n",
      "Epoch 7/100\n",
      "14659/14659 [==============================] - 11s 740us/step - loss: 0.2945 - val_loss: 0.3171\n",
      "Epoch 8/100\n",
      "14659/14659 [==============================] - 11s 725us/step - loss: 0.2943 - val_loss: 0.3166\n",
      "Epoch 9/100\n",
      "14659/14659 [==============================] - 14s 931us/step - loss: 0.2936 - val_loss: 0.3165\n",
      "Epoch 10/100\n",
      "14659/14659 [==============================] - 11s 734us/step - loss: 0.2936 - val_loss: 0.3164\n",
      "Epoch 11/100\n",
      "14659/14659 [==============================] - 11s 768us/step - loss: 0.2936 - val_loss: 0.3164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe7f9fb4c50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3)\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "logdir = os.path.join(\"logs\", f\"SimpleAutoencoder-{now}\")\n",
    "tensorboard = TensorBoard(log_dir=logdir)\n",
    "\n",
    "autoencoder.fit(df, # input image to encoder\n",
    "                df, # provide input image to decoder so the model learns how to reconstruct the input image \n",
    "                epochs=100,\n",
    "                validation_split=.2,\n",
    "                callbacks=[stop, tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow NN Summary:\n",
    "0 hidden layers: Val Loss: 0.3160\n",
    "1 hidden layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((586344, 16), (586344, 26))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_songs = autoencoder.predict(df)\n",
    "encoded_songs = encoder.predict(df)\n",
    "\n",
    "encoded_songs.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=11, algorithm='ball_tree')\n",
    "nn.fit(encoded_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the encoded_songs embedding as a df and the Nearest Neighbours model for use in our app\n",
    "import pickle\n",
    "\n",
    "embeddings_df = pd.DataFrame(encoded_songs, index=df.index)\n",
    "\n",
    "# Saving the embeddings to the disk\n",
    "embeddings_df.to_csv('./saved_models/embeddings_df_001.csv')\n",
    "\n",
    "# save the model to disk\n",
    "filename = './saved_models/nearestneigh_001.sav'\n",
    "pickle.dump(nn, open(filename, 'wb'))\n",
    "\n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = loaded_model.score(X_test, Y_test)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSpot's recommendation system:\n",
      "\n",
      "\n",
      "Top 10 recommendations for California Love by 175588    ['2Pac']\n",
      "Name: artists, dtype: object:\n",
      "\n",
      "Cachoeira de Poder by ['Cassiane'] with a score of 0.0\n",
      "\n",
      "URL: https://open.spotify.com/track/0L8dJ0M42lrXUhhh6H9aN0\n",
      "\n",
      "Fade by ['Devilskin'] with a score of 0.9907773863846817\n",
      "\n",
      "URL: https://open.spotify.com/track/2I3FLnQbeNymsCG1TGDVfX\n",
      "\n",
      "Uhrisavua by ['Hassisen Kone'] with a score of 1.001666262358712\n",
      "\n",
      "URL: https://open.spotify.com/track/70zYdVQQAt0vnkSjW0rcK9\n",
      "\n",
      "Un uomo vivo by ['Tony Dallara'] with a score of 1.0400524260355803\n",
      "\n",
      "URL: https://open.spotify.com/track/0vyq4zoKDJnKx9ED6Fkr01\n",
      "\n",
      "Lääkärissä by ['Veikko Lavi'] with a score of 1.1168803278114197\n",
      "\n",
      "URL: https://open.spotify.com/track/5NGe7LBO4chb0mNEBTrFGK\n",
      "\n",
      "Tiina Tanssii Taas by ['Neljä Ruusua'] with a score of 1.190339226396119\n",
      "\n",
      "URL: https://open.spotify.com/track/0OzCtZgVaU4msnelmnYKPP\n",
      "\n",
      "Sapore di mare by ['NotteNera', 'Tony Haze', 'Explosive Boyz'] with a score of 1.2194868192759052\n",
      "\n",
      "URL: https://open.spotify.com/track/7va2cIgVtcyv1JttJZKGcv\n",
      "\n",
      "Heavy Metal: The Black and Silver by ['Blue Öyster Cult'] with a score of 1.2422895418746867\n",
      "\n",
      "URL: https://open.spotify.com/track/1uUCpOX86yRGShambUp93O\n",
      "\n",
      "Micimackó és barátai Babits Mihály versét éneklik - Live by ['HALÁSZ JUDIT'] with a score of 1.3829279540607726\n",
      "\n",
      "URL: https://open.spotify.com/track/1d0TRVG28smxScm3qGp8pu\n",
      "\n",
      "Fade to Black - Live / Seattle '89 by ['Metallica'] with a score of 1.4879939160127869\n",
      "\n",
      "URL: https://open.spotify.com/track/46GRDe7B3ptpFE7brebD69\n",
      "\n",
      "___________________________________________________________________________________\n",
      "\n",
      "Top 10 recommendations for The Gambler by 51497    ['Kenny Rogers']\n",
      "Name: artists, dtype: object:\n",
      "\n",
      "Puisi Alam by ['Fourtwnty'] with a score of 0.0\n",
      "\n",
      "URL: https://open.spotify.com/track/0k939QxLzPo5UntxR8maXd\n",
      "\n",
      "Dil Hi Toh Hai by ['Pritam', 'Arijit Singh', 'Antara Mitra', \"Nikhil D'Souza\"] with a score of 0.7280432154997473\n",
      "\n",
      "URL: https://open.spotify.com/track/0hpP2fBridGH2Bq6qmg9LM\n",
      "\n",
      "Pepeta by ['Nora Fatehi', 'Rayvanny'] with a score of 0.7364000620078118\n",
      "\n",
      "URL: https://open.spotify.com/track/5a8j5OD7qFql7c8Buy8dm6\n",
      "\n",
      "I Have Nothing by ['Whitney Houston'] with a score of 0.8300029034187858\n",
      "\n",
      "URL: https://open.spotify.com/track/31er9IGsfFbwqy1pH4aiTP\n",
      "\n",
      "Megalodon (Mix Cut) - Original Mix by ['MaRLo'] with a score of 0.8714000994466777\n",
      "\n",
      "URL: https://open.spotify.com/track/3EP2s3NRMQWxvZTe2qYaT1\n",
      "\n",
      "Soltera by ['Agapornis'] with a score of 0.9225277186840652\n",
      "\n",
      "URL: https://open.spotify.com/track/4FZJUfuJ2iWmYQGP049z34\n",
      "\n",
      "We Control The Sunlight [ASOT 541] - Original Mix by ['Aly & Fila', 'Jwaydan'] with a score of 0.9906631734842157\n",
      "\n",
      "URL: https://open.spotify.com/track/3Z55Cj5sbSdtL8L6588QfC\n",
      "\n",
      "False - Alvaro Hylander Remix - Mixed by ['Cadatta', 'Alvaro Hylander'] with a score of 1.0295051010731535\n",
      "\n",
      "URL: https://open.spotify.com/track/32uKnDrjBO0jzdK5SQkj37\n",
      "\n",
      "It's All About Tonight by ['Michael Stanley'] with a score of 1.118271979557577\n",
      "\n",
      "URL: https://open.spotify.com/track/1CrqURBDZh1wiRalmpqC38\n",
      "\n",
      "Cars by ['Gary Numan'] with a score of 1.1436215419305267\n",
      "\n",
      "URL: https://open.spotify.com/track/4QQEzkxcONBthDLfzqIh9S\n",
      "\n",
      "___________________________________________________________________________________\n",
      "\n",
      "Top 10 recommendations for Eye of the Tiger by 117553    ['Survivor']\n",
      "Name: artists, dtype: object:\n",
      "\n",
      "Una Vez Más by ['Grupo Bryndis'] with a score of 0.0\n",
      "\n",
      "URL: https://open.spotify.com/track/37HKATyByFROKQOjaggiPO\n",
      "\n",
      "Te Olvidare by ['Son de Ríos'] with a score of 1.1582567668022925\n",
      "\n",
      "URL: https://open.spotify.com/track/2O3gca1XOt9o4jjt4TYGxX\n",
      "\n",
      "I Won't Send Roses - From \"Mack & Mabel Original Cast Recording\" by ['Robert Preston'] with a score of 1.1660572864713117\n",
      "\n",
      "URL: https://open.spotify.com/track/6olp2w5vTf64dWfW0VlxEy\n",
      "\n",
      "ミルククラウン・オン・ソーネチカ by ['YUZY'] with a score of 1.299613381085936\n",
      "\n",
      "URL: https://open.spotify.com/track/2jxakPQFR2IBXVmvt5y8YB\n",
      "\n",
      "I Want Candy by ['Bow Wow Wow'] with a score of 1.4178316192877023\n",
      "\n",
      "URL: https://open.spotify.com/track/2FMcDUopGfjBh3xMsrm78S\n",
      "\n",
      "Por Tu Amor by ['Autocontrol'] with a score of 1.4413491538093222\n",
      "\n",
      "URL: https://open.spotify.com/track/2IvOjXrJCmttHX8cSKFKbs\n",
      "\n",
      "La Usurpadora by ['Pandora'] with a score of 1.4711609002312327\n",
      "\n",
      "URL: https://open.spotify.com/track/2hWwM1HvqlinY0n9mnC3NW\n",
      "\n",
      "分手要狠 by ['Kary Ng'] with a score of 1.482217065017932\n",
      "\n",
      "URL: https://open.spotify.com/track/4CXqxaa3aZNDVsAJDgk4Jt\n",
      "\n",
      "Etoimazo Taxidi by ['Giorgos Giannias'] with a score of 1.4926574026656896\n",
      "\n",
      "URL: https://open.spotify.com/track/0OQMn5tUPvlpBikaJsYMYa\n",
      "\n",
      "ハナミズキ by ['Yo Hitoto'] with a score of 1.5262273418799581\n",
      "\n",
      "URL: https://open.spotify.com/track/0h9VlXphgiAHN1gQ9xtnNa\n",
      "\n",
      "___________________________________________________________________________________\n",
      "\n",
      "Top 10 recommendations for You are my Sunshine by 121425    ['Kei R Woods']\n",
      "Name: artists, dtype: object:\n",
      "\n",
      "Kein Wort by ['Juju', 'Loredana', 'Miksu / Macloud'] with a score of 0.0\n",
      "\n",
      "URL: https://open.spotify.com/track/1hoLUVBx0ixX3kn0EX0P5n\n",
      "\n",
      "You Are Love by ['Kathryn Grayson', 'Howard Keel'] with a score of 1.0860541590106656\n",
      "\n",
      "URL: https://open.spotify.com/track/1b0YkCZ5kKep4dGHwvD7NP\n",
      "\n",
      "Marta's Lament by ['Marta Mist'] with a score of 1.7825513293665287\n",
      "\n",
      "URL: https://open.spotify.com/track/0hLoW0gbUeEeTfcru6sHaF\n",
      "\n",
      "Delius: 2 Pieces for Small Orchestra: No. 1, On Hearing the First Cuckoo in Spring by ['Frederick Delius', 'Vernon Handley', 'London Philharmonic Orchestra'] with a score of 1.8346849216731624\n",
      "\n",
      "URL: https://open.spotify.com/track/2dEbRirkEtImY7HdYxrgRS\n",
      "\n",
      "Danger by ['Isham Jones'] with a score of 2.122585589015155\n",
      "\n",
      "URL: https://open.spotify.com/track/1C1mR4PoFHKxpOgyJBPd8u\n",
      "\n",
      "VVS by ['Yanix'] with a score of 2.1562985607754497\n",
      "\n",
      "URL: https://open.spotify.com/track/1toU1FjTUi7q5TRpmKgAj4\n",
      "\n",
      "Overture / Unveiling the Monument by ['Charlie Chaplin'] with a score of 2.1851291104030612\n",
      "\n",
      "URL: https://open.spotify.com/track/2XtVyDXly5EAvNXV9y7Uv4\n",
      "\n",
      "Vuelve by ['Agrupación Sin Ley', 'María Juana'] with a score of 2.1851295048471338\n",
      "\n",
      "URL: https://open.spotify.com/track/3118oZeTKkBMnAss3IiLWD\n",
      "\n",
      "Yeah, and Yet More Pink Noises and Sounds for Total Recharge by ['White Noise Baby Sleep Music'] with a score of 2.1851295048471338\n",
      "\n",
      "URL: https://open.spotify.com/track/7y2h3iIHMAmragF0g6Xc2U\n",
      "\n",
      "On Sacrifice and Losses - 04 28 1948 by ['Franklin Delano Roosevelt'] with a score of 2.1851295048471338\n",
      "\n",
      "URL: https://open.spotify.com/track/4WAR5tveNNwaMWC55I9xVC\n",
      "\n",
      "___________________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing our model with the eye of the tiger song\n",
    "raw_df = pd.read_csv('./Data/tracks.csv')\n",
    "\n",
    "test_songs = {'California Love': '0LyLz6XsVs6wz85dK0S6EG', 'The Gambler': '5KqldkCunQ2rWxruMEtGh0', \n",
    "              'Eye of the Tiger': '2HHtWyy5CgaQbC7XSoOb0e', 'You are my Sunshine': '4ApTr4wbyOucy2lbAvyuuV'}\n",
    "\n",
    "# Loop over all our test songs and get the recommendations\n",
    "recommendations = {}\n",
    "\n",
    "print('DeepSpot\\'s recommendation system:\\n\\n')\n",
    "\n",
    "for name, id in test_songs.items():\n",
    "    query = raw_df.index[raw_df['id'] == id][0]\n",
    "    test_song = pd.DataFrame([raw_df.iloc[query, :]])\n",
    "    \n",
    "    score, close_image_idx = nn.kneighbors(encoded_songs[query].reshape(1,-1))\n",
    "    k_closest_songs_indexes = close_image_idx[0][1:]\n",
    "    \n",
    "    print('Top 10 recommendations for {} by {}:\\n'.format(name, test_song.artists))\n",
    "    for i in range(len(k_closest_songs_indexes)):\n",
    "        song = raw_df.iloc[k_closest_songs_indexes[i], :]\n",
    "        print('{} by {} with a score of {}\\n'.format(song['name'], song.artists, score[0][i]))\n",
    "        print('URL: https://open.spotify.com/track/{}\\n'.format(song['id']))\n",
    "    print('___________________________________________________________________________________\\n')\n",
    "    \n",
    "    recommendations[name] = k_closest_songs_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep variational encoder\n",
    "\n",
    "encoded_dim = 16\n",
    "\n",
    "input_song = Input(shape = (df.shape[1], ))\n",
    "\n",
    "encoded_h1 = Dense(64, activation = 'relu')(input_song)\n",
    "encoded_h2 = Dense(32, activation = 'relu')(encoded_h1)\n",
    "encoded = Dense(encoded_dim, activation = 'relu')(encoded_h2)\n",
    "\n",
    "decoded_h1 = Dense(32, activation='relu')(encoded)\n",
    "decoded_h2 = Dense(64, activation='relu')(decoded_h1)\n",
    "decoded = Dense(df.shape[1], activation='sigmoid')(decoded_h2)\n",
    "\n",
    "deep_autoencoder = Model(input_song, decoded) # techincally autoencoder_and_decoder\n",
    "\n",
    "deep_encoder = Model(input_song, encoded) # Half of the autoencoder\n",
    "\n",
    "deep_autoencoder.compile(optimizer='nadam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 10:48:21.670377: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-08-20 10:48:21.670394: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-08-20 10:48:21.670681: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   95/14659 [..............................] - ETA: 32s - loss: 0.5398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-20 10:48:23.282506: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-08-20 10:48:23.282523: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-08-20 10:48:23.344656: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-08-20 10:48:23.347417: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-08-20 10:48:23.350243: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/SimpleAutoencoder-20210820-104821/train/plugins/profile/2021_08_20_10_48_23\n",
      "2021-08-20 10:48:23.352057: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to logs/SimpleAutoencoder-20210820-104821/train/plugins/profile/2021_08_20_10_48_23/Petrs-MBP.trace.json.gz\n",
      "2021-08-20 10:48:23.358046: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/SimpleAutoencoder-20210820-104821/train/plugins/profile/2021_08_20_10_48_23\n",
      "2021-08-20 10:48:23.358273: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to logs/SimpleAutoencoder-20210820-104821/train/plugins/profile/2021_08_20_10_48_23/Petrs-MBP.memory_profile.json.gz\n",
      "2021-08-20 10:48:23.360175: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/SimpleAutoencoder-20210820-104821/train/plugins/profile/2021_08_20_10_48_23Dumped tool data for xplane.pb to logs/SimpleAutoencoder-20210820-104821/train/plugins/profile/2021_08_20_10_48_23/Petrs-MBP.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/SimpleAutoencoder-20210820-104821/train/plugins/profile/2021_08_20_10_48_23/Petrs-MBP.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/SimpleAutoencoder-20210820-104821/train/plugins/profile/2021_08_20_10_48_23/Petrs-MBP.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/SimpleAutoencoder-20210820-104821/train/plugins/profile/2021_08_20_10_48_23/Petrs-MBP.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/SimpleAutoencoder-20210820-104821/train/plugins/profile/2021_08_20_10_48_23/Petrs-MBP.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14015/14659 [===========================>..] - ETA: 0s - loss: 0.3268"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/mg/_r0tzxlj51xd5dqszvs8fvth0000gn/T/ipykernel_2582/3324281904.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m                 \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m                 \u001B[0mvalidation_split\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m.2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m                 callbacks=[stop, tensorboard])\n\u001B[0m",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1181\u001B[0m                 _r=1):\n\u001B[1;32m   1182\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1183\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1184\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1185\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    887\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    891\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    915\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    916\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 917\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    918\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    919\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3022\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m   3023\u001B[0m     return graph_function._call_flat(\n\u001B[0;32m-> 3024\u001B[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m   3025\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3026\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1959\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1960\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0;32m-> 1961\u001B[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[1;32m   1962\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[1;32m   1963\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    594\u001B[0m               \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    595\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 596\u001B[0;31m               ctx=ctx)\n\u001B[0m\u001B[1;32m    597\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    598\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0;32m---> 60\u001B[0;31m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3)\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "logdir = os.path.join(\"logs\", f\"SimpleAutoencoder-{now}\")\n",
    "tensorboard = TensorBoard(log_dir=logdir)\n",
    "\n",
    "deep_autoencoder.fit(df, # input image to encoder\n",
    "                df, # provide input image to decoder so the model learns how to reconstruct the input image \n",
    "                epochs=100,\n",
    "                validation_split=.2,\n",
    "                callbacks=[stop, tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep NN Summary\n",
    "Val loss = 0.2960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_songs = autoencoder.predict(df)\n",
    "encoded_songs = encoder.predict(df)\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=11, algorithm='ball_tree')\n",
    "nn.fit(encoded_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586344, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_songs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSpot's recommendation system:\n",
      "\n",
      "\n",
      "Top 10 recommendations for California Love by 175588    ['2Pac']\n",
      "Name: artists, dtype: object:\n",
      "\n",
      "Juegas con mi corazón by ['UN PINGUINO EN MI ASCENSOR'] with a score of 0.0\n",
      "\n",
      "URL: https://open.spotify.com/track/52CmXkCAPf1uS9Cm0wC0La\n",
      "\n",
      "The Reward of Normativity by ['Stars in Coma'] with a score of 0.014348841391494971\n",
      "\n",
      "URL: https://open.spotify.com/track/3NdKOSTVFDah1iWlxj3Nqk\n",
      "\n",
      "Listen to Your Heart - Edmée's Unplugged Vocal by ['DHT', 'Edmee'] with a score of 0.015060096439184491\n",
      "\n",
      "URL: https://open.spotify.com/track/2Vp612MQxZIk93MDXgi2jB\n",
      "\n",
      "São São Paulo by ['Tom Zé'] with a score of 0.02050260477362888\n",
      "\n",
      "URL: https://open.spotify.com/track/7mDGwz1mDukOiluzeqVpOp\n",
      "\n",
      "Malkata by ['Vanesa', 'Alisia'] with a score of 0.024714428786101007\n",
      "\n",
      "URL: https://open.spotify.com/track/6CF4z1cagBXX5g1lplHT1U\n",
      "\n",
      "Balladi elokuvasta Klaani / Ballad Of The Clan by ['Anssi Tikanmäki'] with a score of 0.024911453539330806\n",
      "\n",
      "URL: https://open.spotify.com/track/60vXabdP3QmS39TBdiPcYs\n",
      "\n",
      "Wild In The Streets by ['Bon Jovi'] with a score of 0.02573722112019629\n",
      "\n",
      "URL: https://open.spotify.com/track/3ZqKjL20uQEqHlZNcP2bZC\n",
      "\n",
      "79 à 99 (Radio Edit) by ['Passi', 'Jmi Sissoko', 'Stomy Bugsy', 'Jacky Brown'] with a score of 0.02693461818886526\n",
      "\n",
      "URL: https://open.spotify.com/track/7BycQVQjWSWOgJ38fnJjgm\n",
      "\n",
      "Yanarım by ['Sertab Erener'] with a score of 0.027564132269433057\n",
      "\n",
      "URL: https://open.spotify.com/track/69dbmLAqR6BTHOvMpZ7XK3\n",
      "\n",
      "Fogo Santo by ['Cassiane'] with a score of 0.028784852825517522\n",
      "\n",
      "URL: https://open.spotify.com/track/5srqQgYSCfE5Jih4ntJtN2\n",
      "\n",
      "___________________________________________________________________________________\n",
      "\n",
      "Top 10 recommendations for The Gambler by 51497    ['Kenny Rogers']\n",
      "Name: artists, dtype: object:\n",
      "\n",
      "Jody by ['America'] with a score of 0.0\n",
      "\n",
      "URL: https://open.spotify.com/track/5LOLaAkgjunrslcdrjjvRb\n",
      "\n",
      "Transpiralo by ['Panico', 'Crazy Girl'] with a score of 0.0051385827710862765\n",
      "\n",
      "URL: https://open.spotify.com/track/0kVQsYbj6AUOm6wytY6i5B\n",
      "\n",
      "Keltinmäki by ['Are'] with a score of 0.011532008124674012\n",
      "\n",
      "URL: https://open.spotify.com/track/6DjFs1i8aEtNJBIu6VP8If\n",
      "\n",
      "Cicatriiices by ['Régulo Caro'] with a score of 0.012395033723086571\n",
      "\n",
      "URL: https://open.spotify.com/track/795iKycRJtgee21MTf9nat\n",
      "\n",
      "Winterlust, Polka, Op. 121 by ['Josef Strauss', 'Lorin Maazel', 'Wiener Philharmoniker'] with a score of 0.01322160801393939\n",
      "\n",
      "URL: https://open.spotify.com/track/2KLO5Nr8flpwc3J8XcOCgW\n",
      "\n",
      "Politician by ['Cream'] with a score of 0.01618401393653233\n",
      "\n",
      "URL: https://open.spotify.com/track/4MYMykrz2e39HaVYutp24u\n",
      "\n",
      "004 - Gefahr im Fitness-Studio - Teil 10 by ['Die drei !!!'] with a score of 0.01715900296971649\n",
      "\n",
      "URL: https://open.spotify.com/track/7i1YL8W6eAFcmwXK0MZJrq\n",
      "\n",
      "Before You Accuse Me - 2013 Remaster by ['Eric Clapton'] with a score of 0.018017944654860625\n",
      "\n",
      "URL: https://open.spotify.com/track/3xsYslIyJbMLk8n9qlUnrb\n",
      "\n",
      "Platano Maduro by ['Nelson Cordero'] with a score of 0.018192901165109163\n",
      "\n",
      "URL: https://open.spotify.com/track/1Jma9i28NacARtJR3QEWAO\n",
      "\n",
      "What's She Like? by ['Roxette'] with a score of 0.020117516832755564\n",
      "\n",
      "URL: https://open.spotify.com/track/2fvm3jbdwHSTLHe1yBA1tU\n",
      "\n",
      "___________________________________________________________________________________\n",
      "\n",
      "Top 10 recommendations for Eye of the Tiger by 117553    ['Survivor']\n",
      "Name: artists, dtype: object:\n",
      "\n",
      "Agresivo by ['Jowell & Randy', 'Arcangel'] with a score of 0.0\n",
      "\n",
      "URL: https://open.spotify.com/track/2kGnzHH1Q6YaxjNylz68CM\n",
      "\n",
      "Kaadu Pottal Kaadu by ['Malasiya', 'Raja'] with a score of 0.04387333795909919\n",
      "\n",
      "URL: https://open.spotify.com/track/3WAg7tTm9QlscDZOUBHbfv\n",
      "\n",
      "Dime Qué Hago by ['Farruko'] with a score of 0.056243062470508066\n",
      "\n",
      "URL: https://open.spotify.com/track/1mXY92e3ReftzcpcoKlsWb\n",
      "\n",
      "Ready Teddy - 2008 Remaster by ['The Swinging Blue Jeans'] with a score of 0.05679522903496801\n",
      "\n",
      "URL: https://open.spotify.com/track/3vf9SWI3f2DWEJ7QH3LEMY\n",
      "\n",
      "ร้องไห้กับเดือน by ['สันติ ดวงสว่าง'] with a score of 0.05712066388954216\n",
      "\n",
      "URL: https://open.spotify.com/track/77S4pdYFGgRn61o8TCmWNb\n",
      "\n",
      "Angel Voice by ['熱気バサラ'] with a score of 0.057733395440670465\n",
      "\n",
      "URL: https://open.spotify.com/track/4hmvJWpwfkPnobS2TZb4dj\n",
      "\n",
      "Twist by ['Tones On Tail'] with a score of 0.058560494338935426\n",
      "\n",
      "URL: https://open.spotify.com/track/3JuWIolTftFRRfLMCK2Qr7\n",
      "\n",
      "The Bird Of Wonder (Live Version) by ['T-SQUARE'] with a score of 0.059187859378664144\n",
      "\n",
      "URL: https://open.spotify.com/track/2LCqaHS9Aw8z3EUC7uDPuc\n",
      "\n",
      "A Bailar by ['La Sonora Matancera', 'Bienvenido Granda'] with a score of 0.0613001027570417\n",
      "\n",
      "URL: https://open.spotify.com/track/3OGjJZNnoOtZfMAIYIGBHV\n",
      "\n",
      "Enyoyando / Can Truenos Hay Que Hablar / Despertar - En Vivo by ['Cultura Profética'] with a score of 0.06131777499447591\n",
      "\n",
      "URL: https://open.spotify.com/track/57xci6chV37mY1GS1BcHPO\n",
      "\n",
      "___________________________________________________________________________________\n",
      "\n",
      "Top 10 recommendations for You are my Sunshine by 121425    ['Kei R Woods']\n",
      "Name: artists, dtype: object:\n",
      "\n",
      "Instrumental - Morutirtha Hinglaj by ['Master Shamik'] with a score of 0.0\n",
      "\n",
      "URL: https://open.spotify.com/track/2AvXOYx3uWaijNgai4ofAw\n",
      "\n",
      "Bona Senzani by ['TKZEE'] with a score of 0.07027942650126705\n",
      "\n",
      "URL: https://open.spotify.com/track/3pkCJeLcM9Fd0xihQcFsIf\n",
      "\n",
      "Piano Concerto No. 1 in D Minor, Op. 15: I. Maestoso by ['Johannes Brahms', 'Gary Graffman', 'Charles Münch'] with a score of 0.0845755624722893\n",
      "\n",
      "URL: https://open.spotify.com/track/1hJ6lqoJyVqFs6qzbfQXZu\n",
      "\n",
      "Gham-E-Ashiana Satayega Kab Tak by ['Suraiya'] with a score of 0.09444017013081589\n",
      "\n",
      "URL: https://open.spotify.com/track/3bSykasL1lQVq66U1e5eAc\n",
      "\n",
      "Microphonophobia by ['Andrzej Kurylewicz Quintet'] with a score of 0.09945844345027532\n",
      "\n",
      "URL: https://open.spotify.com/track/4UJWYlGe2tw4XBRv1JPHaX\n",
      "\n",
      "Janma Metthithira by ['Ghantasala'] with a score of 0.1309595228511349\n",
      "\n",
      "URL: https://open.spotify.com/track/3KdORz3OswlCCyD9oO2QMi\n",
      "\n",
      "Hasta Cuando by ['David Lee Garza', 'Los Musicales'] with a score of 0.1347257635366407\n",
      "\n",
      "URL: https://open.spotify.com/track/2ry3dWDv0IwR22OYEqDZGQ\n",
      "\n",
      "How Do They Know by ['Dogsmile'] with a score of 0.13704136913534806\n",
      "\n",
      "URL: https://open.spotify.com/track/1krCrsxlc0tXH419cr6xIP\n",
      "\n",
      "Perdido - Live At The Newport Jazz Festival, 1957 by ['Carmen McRae'] with a score of 0.1406222649430128\n",
      "\n",
      "URL: https://open.spotify.com/track/79VO66igG74eGQ0kISqkjP\n",
      "\n",
      "אין לאן ללכת (מכורתי א') by ['Ethnix'] with a score of 0.14367616740325156\n",
      "\n",
      "URL: https://open.spotify.com/track/2km85u7g9uTDWgRNptEZsC\n",
      "\n",
      "___________________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing our model with the eye of the tiger song\n",
    "raw_df = pd.read_csv('./Data/tracks.csv')\n",
    "\n",
    "test_songs = {'California Love': '0LyLz6XsVs6wz85dK0S6EG', 'The Gambler': '5KqldkCunQ2rWxruMEtGh0', \n",
    "              'Eye of the Tiger': '2HHtWyy5CgaQbC7XSoOb0e', 'You are my Sunshine': '4ApTr4wbyOucy2lbAvyuuV'}\n",
    "\n",
    "# Loop over all our test songs and get the recommendations\n",
    "recommendations = {}\n",
    "\n",
    "print('DeepSpot\\'s recommendation system:\\n\\n')\n",
    "\n",
    "for name, id in test_songs.items():\n",
    "    query = raw_df.index[raw_df['id'] == id][0]\n",
    "    test_song = pd.DataFrame([raw_df.iloc[query, :]])\n",
    "    \n",
    "    score, close_image_idx = nn.kneighbors(encoded_songs[query].reshape(1,-1))\n",
    "    k_closest_songs_indexes = close_image_idx[0][1:]\n",
    "    \n",
    "    print('Top 10 recommendations for {} by {}:\\n'.format(name, test_song.artists))\n",
    "    for i in range(len(k_closest_songs_indexes)):\n",
    "        song = raw_df.iloc[k_closest_songs_indexes[i], :]\n",
    "        print('{} by {} with a score of {}\\n'.format(song['name'], song.artists, score[0][i]))\n",
    "        print('URL: https://open.spotify.com/track/{}\\n'.format(song['id']))\n",
    "    print('___________________________________________________________________________________\\n')\n",
    "    \n",
    "    recommendations[name] = k_closest_songs_indexes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variational Autoencoder\n",
    "from keras import layers\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"\n",
    "    Uses (z_mean, z_log_var) to sample a z vector from the latent N-dimensional Normal distribution\n",
    "    i.e. Z is the vector encoding a digit.\n",
    "    \"\"\"\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        # recall from the video that z_mean and z_log_var are vectors \n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        \n",
    "        # sample from an N-dimensional normal distribution\n",
    "        # epsilon is given shape (batch, dim) because we are adding it to z_mean which has shape (batch, dim)\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        \n",
    "        # output of tf.exp() is a vector \n",
    "        simga = tf.exp(0.5 * z_log_var)\n",
    "        \n",
    "        # this is our hideen latent vector made up of a mean and variance vector \n",
    "        # variance vector is scaled by epsilon, which is sampled from a normal distribtuion \n",
    "        # the the video guy said \"stocastic\" in reference to epsilon, he meant random \n",
    "        Z = z_mean + simga * epsilon\n",
    "        \n",
    "        # return hidden latent vector \n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 16)           432         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 16)           272         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 16)           272         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_4 (TFOpLambd (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_5 (TFOpLambd (2,)                 0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_4 (TFOpLambda) (None, 16)           0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_4 (Sli ()                   0           tf.compat.v1.shape_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_5 (Sli ()                   0           tf.compat.v1.shape_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp_2 (TFOpLambda)      (None, 16)           0           tf.math.multiply_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.random.normal_2 (TFOpLambda) (None, None)         0           tf.__operators__.getitem_4[0][0] \n",
      "                                                                 tf.__operators__.getitem_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_5 (TFOpLambda) (None, 16)           0           tf.math.exp_2[0][0]              \n",
      "                                                                 tf.random.normal_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 16)           0           z_mean[0][0]                     \n",
      "                                                                 tf.math.multiply_5[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 976\n",
      "Trainable params: 976\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# recall from the video that the more dimensions that our latent vector has\n",
    "# the better the results of our model \n",
    "latent_dim = 16\n",
    "\n",
    "# shape of our input data\n",
    "# we are creating our input layer using Keras's Input() class\n",
    "# the only thing that input layers really do is define the dimensionality of the input data for the model\n",
    "encoder_inputs = Input(shape=(df.shape[1], ))\n",
    "\n",
    "# these are the hidden layers\n",
    "\n",
    "# pass data vector into FCFF layer \n",
    "encoded = Dense(encoded_dim, activation = 'relu')(encoder_inputs)\n",
    "\n",
    "# recall that ordinarly the output of the last encoding layer is the latent vector \n",
    "# but here we are creating two output layers for our encoder - one for the mean and one for the log variance \n",
    "# returns a 2-dim mean vector\n",
    "z_mean = Dense(latent_dim, name=\"z_mean\")(encoded)\n",
    "# returns a 2-dim log variance vecotr \n",
    "z_log_var = Dense(latent_dim, name=\"z_log_var\")(encoded)\n",
    "# pass mean and variance vector into Sampling class in order to create the Z vector,  Z = mean + var * epsilon\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "# ok, now let's put it all together \n",
    "# this is our encoder model \n",
    "# inputs are the original images\n",
    "# outputs are the Z vectors: mean, log variance, and the complete Z, i.e. vector Z = mean + var * epsilon\n",
    "encoder = Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 26)                442       \n",
      "=================================================================\n",
      "Total params: 442\n",
      "Trainable params: 442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the input layer to our decoder has the same dimensionality as the latent vector\n",
    "# because the latent vector is the input to the decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,))\n",
    "\n",
    "# these are the hidden layers of our decoder \n",
    "# the data at this point is in a vector, the Z latent vector \n",
    "\n",
    "# this is the final layer in out decoder\n",
    "# therefore this layer outputs the reconstruction of the original image \n",
    "decoder_outputs = Dense(df.shape[1], activation='sigmoid')(latent_inputs)\n",
    "\n",
    "# this is our decoder model \n",
    "decoder = Model(inputs=latent_inputs, outputs=decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        \"\"\"\n",
    "        This class build a Variational Auto-Encoder. It accepts an Encoder and Decoder model as input. \n",
    "        \n",
    "        Note\n",
    "        ----\n",
    "        This VAE class is inheriting Keras's Model API so that it can use the Model class methods \n",
    "\n",
    "        \"\"\"\n",
    "        # how python 3 handels inheritance \n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        # set encoder model as class attribute\n",
    "        self.encoder = encoder\n",
    "        # set decoder model as class attribute \n",
    "        self.decoder = decoder\n",
    "        # set mean function as class attribute - this calculates the total loss\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        # set mean function as class attribute - this calculates the reconstruction loss\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        # set mean function as class attribute - this calculates the kl loss\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        \"\"\"\n",
    "        Returns all loses in a list\n",
    "        \"\"\"\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \"\"\"\n",
    "        Training our model via gradient descent and back-propagation \n",
    "        \"\"\"\n",
    "        \n",
    "        # we used tf.GradientTape() in Sprint 2 Module 2 to run Gradient Descent from scratch \n",
    "        with tf.GradientTape() as tape:\n",
    "            # pass input data into encoder model \n",
    "            # output of encoder model is the hidden state distribution parameters and hidden state vector \n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            \n",
    "            # pass hidden state vector into decoder model \n",
    "            reconstruction = self.decoder(z)\n",
    "            \n",
    "            # calculate the reconstruction loss \n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.MeanSquaredError(data, reconstruction)#, axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # calculate the kl loss\n",
    "            #                (1 + z_simga   - (z_mean)^2        - e^(z_simga) ) \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            # recall that we used tf.reduce_sum() in Sprint 2 Module 4 assignment \n",
    "            # it takes the sum of the vector components \n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            \n",
    "            # calculate the total loss by adding the two loss components \n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            \n",
    "        # now that we have calculated the loss function, we can perform Gradient Descent\n",
    "        # we are passing in the loss function and the weights that we want to update via Gradeint Descent \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        # log the total loss\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        \n",
    "        # log the reconsgrution loss \n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        \n",
    "        # log the kl loss \n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        # return all the losses in a dictionary \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /var/folders/mg/_r0tzxlj51xd5dqszvs8fvth0000gn/T/ipykernel_2582/1356238690.py:54 train_step\n        keras.losses.MeanSquaredError(data, reconstruction)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:325 __init__\n        mean_squared_error, name=name, reduction=reduction)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:241 __init__\n        super(LossFunctionWrapper, self).__init__(reduction=reduction, name=name)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:102 __init__\n        losses_utils.ReductionV2.validate(reduction)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:76 validate\n        if key not in cls.all():\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1800 tensor_equals\n        self, other = maybe_promote_tensors(self, other)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1202 maybe_promote_tensors\n        ops.convert_to_tensor(tensor, dtype, name=\"x\"))\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1566 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:265 constant\n        allow_broadcast=True)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:283 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:457 make_tensor_proto\n        _AssertCompatible(values, dtype)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:337 _AssertCompatible\n        (dtype.name, repr(mismatch), type(mismatch).__name__))\n\n    TypeError: Expected float64, got 'auto' of type 'str' instead.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/mg/_r0tzxlj51xd5dqszvs8fvth0000gn/T/ipykernel_2582/148974468.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;31m# train the model weights\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mvae\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mworkers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;31m# if you have access to multiple processors, set parameter `workers` to N - 1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;31m# where N is the total number of processors that you have\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1181\u001B[0m                 _r=1):\n\u001B[1;32m   1182\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1183\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1184\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1185\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    887\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    891\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    931\u001B[0m       \u001B[0;31m# This is the first call of __call__, so we have to initialize.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    932\u001B[0m       \u001B[0minitializers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 933\u001B[0;31m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_initialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madd_initializers_to\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitializers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    934\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    935\u001B[0m       \u001B[0;31m# At this point we know that the initialization is complete (or less\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_initialize\u001B[0;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[1;32m    762\u001B[0m     self._concrete_stateful_fn = (\n\u001B[1;32m    763\u001B[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001B[0;32m--> 764\u001B[0;31m             *args, **kwds))\n\u001B[0m\u001B[1;32m    765\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    766\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minvalid_creator_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0munused_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0munused_kwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_get_concrete_function_internal_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3048\u001B[0m       \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3049\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3050\u001B[0;31m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3051\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3052\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3442\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3443\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3444\u001B[0;31m           \u001B[0mgraph_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3445\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3446\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3287\u001B[0m             \u001B[0marg_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marg_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3288\u001B[0m             \u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3289\u001B[0;31m             capture_by_value=self._capture_by_value),\n\u001B[0m\u001B[1;32m   3290\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_attributes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3291\u001B[0m         \u001B[0mfunction_spec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_spec\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m    997\u001B[0m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    998\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 999\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1000\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1001\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    670\u001B[0m         \u001B[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    671\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcompile_with_xla\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 672\u001B[0;31m           \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    673\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    674\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    984\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    985\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 986\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    987\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    988\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: in user code:\n\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /var/folders/mg/_r0tzxlj51xd5dqszvs8fvth0000gn/T/ipykernel_2582/1356238690.py:54 train_step\n        keras.losses.MeanSquaredError(data, reconstruction)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:325 __init__\n        mean_squared_error, name=name, reduction=reduction)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:241 __init__\n        super(LossFunctionWrapper, self).__init__(reduction=reduction, name=name)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:102 __init__\n        losses_utils.ReductionV2.validate(reduction)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:76 validate\n        if key not in cls.all():\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1800 tensor_equals\n        self, other = maybe_promote_tensors(self, other)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1202 maybe_promote_tensors\n        ops.convert_to_tensor(tensor, dtype, name=\"x\"))\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1566 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:265 constant\n        allow_broadcast=True)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:283 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:457 make_tensor_proto\n        _AssertCompatible(values, dtype)\n    /opt/anaconda3/envs/Unit_4/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:337 _AssertCompatible\n        (dtype.name, repr(mismatch), type(mismatch).__name__))\n\n    TypeError: Expected float64, got 'auto' of type 'str' instead.\n"
     ]
    }
   ],
   "source": [
    "# instantiate a Variational Auto-Encoder model \n",
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "# complie the model \n",
    "vae.compile(optimizer=keras.optimizers.Nadam())\n",
    "\n",
    "# train the model weights \n",
    "vae.fit(df, epochs=10, workers=10)\n",
    "# if you have access to multiple processors, set parameter `workers` to N - 1\n",
    "# where N is the total number of processors that you have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "autoencoder.save('saved_model/autoencoder_002')\n",
    "encoder.save('saved_model/encoder_002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Unit_4 (Python3)",
   "language": "python",
   "name": "unit_4p"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}