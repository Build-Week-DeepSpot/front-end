{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "# from ipynb.fs.full.Preprocessing import clean_data\n",
    "%load_ext tensorboard\n",
    "\n",
    "# df = pd.read_csv('./Data/songs_cleaned.csv', index_col='Unnamed: 0')\n",
    "# print(df.shape)\n",
    "# df.describe()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv('data/songs_cleaned.csv', index_col='Unnamed: 0')\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/songs_cleaned.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-071817c09e81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/songs_cleaned.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         )\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             )\n\u001b[1;32m    654\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/songs_cleaned.csv'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Simple autoencoder\n",
    "\n",
    "encoded_dim = 16\n",
    "\n",
    "input_song = Input(shape = (df.shape[1], ))\n",
    "\n",
    "h1 = Dense(32, activation = 'relu')(input_song)\n",
    "\n",
    "encoded = Dense(encoded_dim, activation = 'relu')(h1)\n",
    "\n",
    "dh1 = Dense(32, activation='sigmoid')(encoded)\n",
    "\n",
    "decoded = Dense(df.shape[1], activation='sigmoid')(dh1)\n",
    "\n",
    "autoencoder = Model(input_song, decoded)\n",
    "\n",
    "encoder = Model(input_song, encoded)\n",
    "\n",
    "autoencoder.compile(optimizer='nadam', loss='mean_squared_error')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3)\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "logdir = os.path.join(\"logs\", f\"SimpleAutoencoder-{now}\")\n",
    "tensorboard = TensorBoard(log_dir=logdir)\n",
    "\n",
    "autoencoder.fit(df, # input image to encoder\n",
    "                df, # provide input image to decoder so the model learns how to reconstruct the input image \n",
    "                epochs=100,\n",
    "                validation_split=.2,\n",
    "                callbacks=[stop, tensorboard])"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Shallow NN Summary:\n",
    "0 hidden layers: Val Loss: 0.3160\n",
    "1 hidden layer: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "decoded_songs = autoencoder.predict(df)\n",
    "encoded_songs = encoder.predict(df)\n",
    "\n",
    "embeddings_df = pd.DataFrame(encoded_songs, index=df.index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(embeddings_df.shape)\n",
    "embeddings_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=11, algorithm='ball_tree')\n",
    "nn.fit(encoded_songs)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(encoded_songs[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Saving the encoded_songs embedding as a df and the Nearest Neighbours model for use in our app\n",
    "import pickle\n",
    "\n",
    "embeddings_df = pd.DataFrame(encoded_songs, index=df.index)\n",
    "\n",
    "# Saving the embeddings to the disk\n",
    "embeddings_df.to_csv('data/autoencoder_embeddings.csv')\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'autoencoder_nn_model.sav'\n",
    "pickle.dump(nn, open(filename, 'wb'))\n",
    "\n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = loaded_model.score(X_test, Y_test)\n",
    "#print(result)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "embeddings_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Testing our model with multiple songs\n",
    "raw_df = pd.read_csv('./Data/tracks.csv')\n",
    "\n",
    "test_songs = {'California Love': '0LyLz6XsVs6wz85dK0S6EG', 'The Gambler': '5KqldkCunQ2rWxruMEtGh0', \n",
    "              'Eye of the Tiger': '2HHtWyy5CgaQbC7XSoOb0e', 'You are my Sunshine': '4ApTr4wbyOucy2lbAvyuuV'}\n",
    "\n",
    "# Loop over all our test songs and get the recommendations\n",
    "recommendations = {}\n",
    "\n",
    "print('DeepSpot\\'s recommendation system:\\n\\n')\n",
    "\n",
    "for name, id in test_songs.items():\n",
    "    query = raw_df.index[raw_df['id'] == id][0]\n",
    "    test_song = pd.DataFrame([raw_df.iloc[query, :]])\n",
    "    \n",
    "    score, close_image_idx = nn.kneighbors(encoded_songs[query].reshape(1,-1))\n",
    "    k_closest_songs_indexes = close_image_idx[0][1:]\n",
    "    \n",
    "    print('Top 10 recommendations for {} by {}:\\n'.format(name, test_song.artists))\n",
    "    for i in range(len(k_closest_songs_indexes)):\n",
    "        song = raw_df.iloc[k_closest_songs_indexes[i], :]\n",
    "        print('{} by {} with a score of {}\\n'.format(song['name'], song.artists, score[0][1:][i]))\n",
    "        print('URL: https://open.spotify.com/track/{}\\n'.format(song['id']))\n",
    "    print('___________________________________________________________________________________\\n')\n",
    "    \n",
    "    recommendations[name] = k_closest_songs_indexes\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Deep variational encoder\n",
    "\n",
    "encoded_dim = 16\n",
    "\n",
    "input_song = Input(shape = (df.shape[1], ))\n",
    "\n",
    "encoded_h1 = Dense(64, activation = 'relu')(input_song)\n",
    "encoded_h2 = Dense(32, activation = 'relu')(encoded_h1)\n",
    "encoded = Dense(encoded_dim, activation = 'relu')(encoded_h2)\n",
    "\n",
    "decoded_h1 = Dense(32, activation='relu')(encoded)\n",
    "decoded_h2 = Dense(64, activation='relu')(decoded_h1)\n",
    "decoded = Dense(df.shape[1], activation='sigmoid')(decoded_h2)\n",
    "\n",
    "deep_autoencoder = Model(input_song, decoded) # techincally autoencoder_and_decoder\n",
    "\n",
    "deep_encoder = Model(input_song, encoded) # Half of the autoencoder\n",
    "\n",
    "deep_autoencoder.compile(optimizer='nadam', loss='mean_squared_error')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3)\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "logdir = os.path.join(\"logs\", f\"SimpleAutoencoder-{now}\")\n",
    "tensorboard = TensorBoard(log_dir=logdir)\n",
    "\n",
    "deep_autoencoder.fit(df, # input image to encoder\n",
    "                df, # provide input image to decoder so the model learns how to reconstruct the input image \n",
    "                epochs=100,\n",
    "                validation_split=.2,\n",
    "                callbacks=[stop, tensorboard])"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deep NN Summary\n",
    "Val loss = 0.2960"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "decoded_songs = autoencoder.predict(df)\n",
    "encoded_songs = encoder.predict(df)\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=11, algorithm='ball_tree')\n",
    "nn.fit(encoded_songs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "encoded_songs.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # Testing\n",
    "# raw_df = pd.read_csv('./Data/tracks.csv')\n",
    "\n",
    "# test_songs = {'California Love': '0LyLz6XsVs6wz85dK0S6EG', 'The Gambler': '5KqldkCunQ2rWxruMEtGh0', \n",
    "#               'Eye of the Tiger': '2HHtWyy5CgaQbC7XSoOb0e', 'You are my Sunshine': '4ApTr4wbyOucy2lbAvyuuV'}\n",
    "\n",
    "# # Loop over all our test songs and get the recommendations\n",
    "# recommendations = {}\n",
    "\n",
    "# print('DeepSpot\\'s recommendation system:\\n\\n')\n",
    "\n",
    "# for name, id in test_songs.items():\n",
    "#     query = raw_df.index[raw_df['id'] == id][0]\n",
    "#     test_song = pd.DataFrame([raw_df.iloc[query, :]])\n",
    "    \n",
    "#     score, close_image_idx = nn.kneighbors(encoded_songs[query].reshape(1,-1))\n",
    "#     k_closest_songs_indexes = close_image_idx[0][1:]\n",
    "    \n",
    "#     print('Top 10 recommendations for {} by {}:\\n'.format(name, test_song.artists))\n",
    "#     for i in range(len(k_closest_songs_indexes)):\n",
    "#         song = raw_df.iloc[k_closest_songs_indexes[i], :]\n",
    "#         print('{} by {} with a score of {}\\n'.format(song['name'], song.artists, score[0][1:][i]))\n",
    "#         print('URL: https://open.spotify.com/track/{}\\n'.format(song['id']))\n",
    "#     print('___________________________________________________________________________________\\n')\n",
    "    \n",
    "#     recommendations[name] = k_closest_songs_indexes\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training a Variational Autoencoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Variational Autoencoder\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"\n",
    "    Uses (z_mean, z_log_var) to sample a z vector from the latent N-dimensional Normal distribution\n",
    "    i.e. Z is the vector encoding a digit.\n",
    "    \"\"\"\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        # recall from the video that z_mean and z_log_var are vectors \n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        \n",
    "        # sample from an N-dimensional normal distribution\n",
    "        # epsilon is given shape (batch, dim) because we are adding it to z_mean which has shape (batch, dim)\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        \n",
    "        # output of tf.exp() is a vector \n",
    "        simga = tf.exp(0.5 * z_log_var)\n",
    "        \n",
    "        # this is our hideen latent vector made up of a mean and variance vector \n",
    "        # variance vector is scaled by epsilon, which is sampled from a normal distribtuion \n",
    "        # the the video guy said \"stocastic\" in reference to epsilon, he meant random \n",
    "        Z = z_mean + simga * epsilon\n",
    "        \n",
    "        # return hidden latent vector \n",
    "        return Z"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "df = pd.read_csv('../../songs_cleaned_autoencoder_8_24.csv', index_col='Unnamed: 0')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "df.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   popularity  duration_ms  explicit  danceability    energy  key_1  key_2  \\\n",
       "0   -1.153128    -0.765231 -0.218921      0.476586 -0.390370      1      0   \n",
       "1   -1.480897    -0.978657 -0.218921      0.776863 -1.112757      1      0   \n",
       "\n",
       "   key_3  key_4  key_5  ...  key_12  loudness  mode  speechiness  \\\n",
       "0      0      0      0  ...       0 -0.593681     1     1.669464   \n",
       "1      0      0      0  ...       0 -2.308889     1     4.199676   \n",
       "\n",
       "   acousticness  instrumentalness  liveness   valence     tempo  \\\n",
       "0      0.637973          2.373142 -0.361517 -1.670382 -0.457098   \n",
       "1      0.990898         -0.422701 -0.377335  0.383636 -0.552432   \n",
       "\n",
       "   time_signature  \n",
       "0       -1.772010  \n",
       "1       -5.847677  \n",
       "\n",
       "[2 rows x 26 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>...</th>\n",
       "      <th>key_12</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.153128</td>\n",
       "      <td>-0.765231</td>\n",
       "      <td>-0.218921</td>\n",
       "      <td>0.476586</td>\n",
       "      <td>-0.390370</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.593681</td>\n",
       "      <td>1</td>\n",
       "      <td>1.669464</td>\n",
       "      <td>0.637973</td>\n",
       "      <td>2.373142</td>\n",
       "      <td>-0.361517</td>\n",
       "      <td>-1.670382</td>\n",
       "      <td>-0.457098</td>\n",
       "      <td>-1.772010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.480897</td>\n",
       "      <td>-0.978657</td>\n",
       "      <td>-0.218921</td>\n",
       "      <td>0.776863</td>\n",
       "      <td>-1.112757</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.308889</td>\n",
       "      <td>1</td>\n",
       "      <td>4.199676</td>\n",
       "      <td>0.990898</td>\n",
       "      <td>-0.422701</td>\n",
       "      <td>-0.377335</td>\n",
       "      <td>0.383636</td>\n",
       "      <td>-0.552432</td>\n",
       "      <td>-5.847677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "encoded_dim = 16\n",
    "\n",
    "# recall from the video that the more dimensions that our latent vector has\n",
    "# the better the results of our model \n",
    "latent_dim = 8\n",
    "\n",
    "# shape of our input data\n",
    "# we are creating our input layer using Keras's Input() class\n",
    "# the only thing that input layers really do is define the dimensionality of the input data for the model\n",
    "encoder_inputs = Input(shape=(df.shape[1], ))\n",
    "\n",
    "# these are the hidden layers\n",
    "\n",
    "# pass data vector into FCFF layer \n",
    "encoded = Dense(encoded_dim, activation = 'relu')(encoder_inputs)\n",
    "\n",
    "# recall that ordinarly the output of the last encoding layer is the latent vector \n",
    "# but here we are creating two output layers for our encoder - one for the mean and one for the log variance \n",
    "# returns a 2-dim mean vector\n",
    "z_mean = Dense(latent_dim, name=\"z_mean\")(encoded)\n",
    "# returns a 2-dim log variance vecotr \n",
    "z_log_var = Dense(latent_dim, name=\"z_log_var\")(encoded)\n",
    "# pass mean and variance vector into Sampling class in order to create the Z vector,  Z = mean + var * epsilon\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "# ok, now let's put it all together \n",
    "# this is our encoder model \n",
    "# inputs are the original images\n",
    "# outputs are the Z vectors: mean, log variance, and the complete Z, i.e. vector Z = mean + var * epsilon\n",
    "encoder = Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           432         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 8)            136         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 8)            136         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sampling_1 (Sampling)           (None, 8)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 704\n",
      "Trainable params: 704\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# the input layer to our decoder has the same dimensionality as the latent vector\n",
    "# because the latent vector is the input to the decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,))\n",
    "\n",
    "# these are the hidden layers of our decoder \n",
    "# the data at this point is in a vector, the Z latent vector \n",
    "\n",
    "# this is the final layer in out decoder\n",
    "# therefore this layer outputs the reconstruction of the original image \n",
    "decoder_outputs = Dense(df.shape[1], activation='sigmoid')(latent_inputs)\n",
    "\n",
    "# this is our decoder model \n",
    "decoder = Model(inputs=latent_inputs, outputs=decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 26)                234       \n",
      "=================================================================\n",
      "Total params: 234\n",
      "Trainable params: 234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        \"\"\"\n",
    "        This class build a Variational Auto-Encoder. It accepts an Encoder and Decoder model as input. \n",
    "        \n",
    "        Note\n",
    "        ----\n",
    "        This VAE class is inheriting Keras's Model API so that it can use the Model class methods \n",
    "\n",
    "        \"\"\"\n",
    "        # how python 3 handels inheritance \n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        # set encoder model as class attribute\n",
    "        self.encoder = encoder\n",
    "        # set decoder model as class attribute \n",
    "        self.decoder = decoder\n",
    "        # set mean function as class attribute - this calculates the total loss\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        # set mean function as class attribute - this calculates the reconstruction loss\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        # set mean function as class attribute - this calculates the kl loss\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        \"\"\"\n",
    "        Returns all loses in a list\n",
    "        \"\"\"\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \"\"\"\n",
    "        Training our model via gradient descent and back-propagation \n",
    "        \"\"\"\n",
    "        \n",
    "        # we used tf.GradientTape() in Sprint 2 Module 2 to run Gradient Descent from scratch \n",
    "        with tf.GradientTape() as tape:\n",
    "            # pass input data into encoder model \n",
    "            # output of encoder model is the hidden state distribution parameters and hidden state vector \n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            \n",
    "            # pass hidden state vector into decoder model \n",
    "            reconstruction = self.decoder(z)\n",
    "            \n",
    "            # calculate the reconstruction loss \n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mse(data, reconstruction)#, axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # calculate the kl loss\n",
    "            #                (1 + z_simga   - (z_mean)^2        - e^(z_simga) ) \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            # recall that we used tf.reduce_sum() in Sprint 2 Module 4 assignment \n",
    "            # it takes the sum of the vector components \n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            \n",
    "            # calculate the total loss by adding the two loss components \n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            \n",
    "        # now that we have calculated the loss function, we can perform Gradient Descent\n",
    "        # we are passing in the loss function and the weights that we want to update via Gradeint Descent \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        # log the total loss\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        \n",
    "        # log the reconstruction loss \n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        \n",
    "        # log the kl loss \n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        # return all the losses in a dictionary \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# instantiate a Variational Auto-Encoder model \n",
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "# complie the model \n",
    "vae.compile(optimizer=keras.optimizers.Nadam())\n",
    "\n",
    "stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=3, restore_best_weights=True)\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "logdir = os.path.join(\"logs\", f\"VAE-{now}\")\n",
    "tensorboard = TensorBoard(log_dir=logdir)\n",
    "\n",
    "# train the model weights \n",
    "vae.fit(df, epochs=100,\n",
    "        callbacks=[stop, tensorboard])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Please provide as model inputs either a single array or a list of arrays. You passed: inputs=        popularity  duration_ms  explicit  danceability    energy  key_1  \\\n0        -1.153128    -0.765231 -0.218921      0.476586 -0.390370      1   \n1        -1.480897    -0.978657 -0.218921      0.776863 -1.112757      1   \n2        -1.480897    -0.358223 -0.218921     -0.790583 -1.454105      0   \n3        -1.480897    -0.393417 -0.218921     -1.469210 -1.781164      0   \n4        -1.480897    -0.496230 -0.218921     -0.982761 -1.529520      0   \n...            ...          ...       ...           ...       ...    ...   \n446470    2.124566    -0.331381 -0.218921     -0.021874 -2.025268      0   \n446471    1.250514     0.211551 -0.218921     -0.033885 -0.100621      1   \n446472    2.452335    -0.569003 -0.218921      1.197251  0.474908      1   \n446473    2.343079    -0.313899 -0.218921     -0.184024 -0.910330      0   \n446474    1.687540    -0.652952 -0.218921      0.782869  0.284388      0   \n\n        key_2  key_3  key_4  key_5  ...  key_12  loudness  mode  speechiness  \\\n0           0      0      0      0  ...       0 -0.593681     1     1.669464   \n1           0      0      0      0  ...       0 -2.308889     1     4.199676   \n2           1      0      0      0  ...       0 -2.122512     1    -0.329704   \n3           0      1      0      0  ...       0 -3.444497     1    -0.333705   \n4           0      0      1      0  ...       0 -1.288108     0    -0.390709   \n...       ...    ...    ...    ...  ...     ...       ...   ...          ...   \n446470      1      0      0      0  ...       0 -2.974658     1    -0.070682   \n446471      0      0      0      0  ...       0  0.550116     0    -0.439713   \n446472      0      0      0      0  ...       0  0.988373     1    -0.259698   \n446473      0      1      0      0  ...       0 -0.493280     0    -0.381709   \n446474      0      0      0      0  ...       0  0.795563     1    -0.413211   \n\n        acousticness  instrumentalness  liveness   valence     tempo  \\\n0           0.637973          2.373142 -0.361517 -1.670382 -0.457098   \n1           0.990898         -0.422701 -0.377335  0.383636 -0.552432   \n2           1.556151         -0.340780 -0.039884 -0.386621  0.400537   \n3           1.559021          3.027009 -0.609333 -0.620032  1.727630   \n4           1.541805          0.065820  0.482112 -1.401959 -0.511809   \n...              ...               ...       ...       ...       ...   \n446470      1.561890          3.188596 -0.572424 -0.662824 -1.837627   \n446471      0.956466         -0.422701 -0.816022 -1.343607  0.450116   \n446472     -0.891369         -0.421585 -0.670496  0.504232  1.060461   \n446473      1.272090         -0.422137 -0.696860 -1.906516  0.892872   \n446474     -0.704864         -0.422692  0.450476 -0.460534 -0.954297   \n\n        time_signature  \n0            -1.772010  \n1            -5.847677  \n2             2.303657  \n3            -1.772010  \n4             0.265824  \n...                ...  \n446470       -1.772010  \n446471        0.265824  \n446472        0.265824  \n446473        0.265824  \n446474        0.265824  \n\n[446198 rows x 26 columns]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3f14192137b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# train the model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m vae.fit(df, epochs=100,\n\u001b[0;32m---> 15\u001b[0;31m         callbacks=[stop, tensorboard])\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m   2580\u001b[0m     \u001b[0;31m# or lists of arrays, and extract a flat list of inputs from the passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2581\u001b[0m     \u001b[0;31m# structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2582\u001b[0;31m     \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_input_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/U4-S2-NN/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mvalidate_input_types\u001b[0;34m(inp, orig_inp, allow_dict, field_name)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     raise ValueError(\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m'Please provide as model inputs either a single array or a list of '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         'arrays. You passed: {}={}'.format(field_name, orig_inp))\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide as model inputs either a single array or a list of arrays. You passed: inputs=        popularity  duration_ms  explicit  danceability    energy  key_1  \\\n0        -1.153128    -0.765231 -0.218921      0.476586 -0.390370      1   \n1        -1.480897    -0.978657 -0.218921      0.776863 -1.112757      1   \n2        -1.480897    -0.358223 -0.218921     -0.790583 -1.454105      0   \n3        -1.480897    -0.393417 -0.218921     -1.469210 -1.781164      0   \n4        -1.480897    -0.496230 -0.218921     -0.982761 -1.529520      0   \n...            ...          ...       ...           ...       ...    ...   \n446470    2.124566    -0.331381 -0.218921     -0.021874 -2.025268      0   \n446471    1.250514     0.211551 -0.218921     -0.033885 -0.100621      1   \n446472    2.452335    -0.569003 -0.218921      1.197251  0.474908      1   \n446473    2.343079    -0.313899 -0.218921     -0.184024 -0.910330      0   \n446474    1.687540    -0.652952 -0.218921      0.782869  0.284388      0   \n\n        key_2  key_3  key_4  key_5  ...  key_12  loudness  mode  speechiness  \\\n0           0      0      0      0  ...       0 -0.593681     1     1.669464   \n1           0      0      0      0  ...       0 -2.308889     1     4.199676   \n2           1      0      0      0  ...       0 -2.122512     1    -0.329704   \n3           0      1      0      0  ...       0 -3.444497     1    -0.333705   \n4           0      0      1      0  ...       0 -1.288108     0    -0.390709   \n...       ...    ...    ...    ...  ...     ...       ...   ...          ...   \n446470      1      0      0      0  ...       0 -2.974658     1    -0.070682   \n446471      0      0      0      0  ...       0  0.550116     0    -0.439713   \n446472      0      0      0      0  ...       0  0.988373     1    -0.259698   \n446473      0      1      0      0  ...       0 -0.493280     0    -0.381709   \n446474      0      0      0      0  ...       0  0.795563     1    -0.413211   \n\n        acousticness  instrumentalness  liveness   valence     tempo  \\\n0           0.637973          2.373142 -0.361517 -1.670382 -0.457098   \n1           0.990898         -0.422701 -0.377335  0.383636 -0.552432   \n2           1.556151         -0.340780 -0.039884 -0.386621  0.400537   \n3           1.559021          3.027009 -0.609333 -0.620032  1.727630   \n4           1.541805          0.065820  0.482112 -1.401959 -0.511809   \n...              ...               ...       ...       ...       ...   \n446470      1.561890          3.188596 -0.572424 -0.662824 -1.837627   \n446471      0.956466         -0.422701 -0.816022 -1.343607  0.450116   \n446472     -0.891369         -0.421585 -0.670496  0.504232  1.060461   \n446473      1.272090         -0.422137 -0.696860 -1.906516  0.892872   \n446474     -0.704864         -0.422692  0.450476 -0.460534 -0.954297   \n\n        time_signature  \n0            -1.772010  \n1            -5.847677  \n2             2.303657  \n3            -1.772010  \n4             0.265824  \n...                ...  \n446470       -1.772010  \n446471        0.265824  \n446472        0.265824  \n446473        0.265824  \n446474        0.265824  \n\n[446198 rows x 26 columns]"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VAE Summary:\n",
    "loss: 15.5321 - reconstruction_loss: 13.6563 - kl_loss: 1.9151"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Encoding our songs\n",
    "z_mean, z_log_var, z = vae.encoder.predict(df)\n",
    "\n",
    "embeddings_df = pd.DataFrame(z, index=df.index)\n",
    "\n",
    "# fitting KNN\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=11, algorithm='ball_tree')\n",
    "nn.fit(z)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Testing the VAE - It seems to work!\n",
    "raw_df = pd.read_csv('./Data/tracks.csv')\n",
    "\n",
    "test_songs = {'California Love': '0LyLz6XsVs6wz85dK0S6EG', 'The Gambler': '5KqldkCunQ2rWxruMEtGh0', \n",
    "              'Eye of the Tiger': '2HHtWyy5CgaQbC7XSoOb0e', 'You are my Sunshine': '4ApTr4wbyOucy2lbAvyuuV'}\n",
    "\n",
    "# Loop over all our test songs and get the recommendations\n",
    "recommendations = {}\n",
    "\n",
    "print('DeepSpot\\'s recommendation system:\\n\\n')\n",
    "\n",
    "for name, id in test_songs.items():\n",
    "    query = raw_df.index[raw_df['id'] == id][0]\n",
    "    test_song = pd.DataFrame([raw_df.iloc[query, :]])\n",
    "    \n",
    "    score, close_image_idx = nn.kneighbors(z[query].reshape(1,-1))\n",
    "    k_closest_songs_indexes = close_image_idx[0][1:]\n",
    "    \n",
    "    print('Top 10 recommendations for {} by {}:\\n'.format(name, test_song.artists))\n",
    "    for i in range(len(k_closest_songs_indexes)):\n",
    "        song = raw_df.iloc[k_closest_songs_indexes[i], :]\n",
    "        print('{} by {} with a score of {}\\n'.format(song['name'], song.artists, score[0][1:][i]))\n",
    "        print('URL: https://open.spotify.com/track/{}\\n'.format(song['id']))\n",
    "    print('___________________________________________________________________________________\\n')\n",
    "    \n",
    "    recommendations[name] = k_closest_songs_indexes\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter tuning the VAE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "latent_dim = 8\n",
    "\n",
    "encoder_inputs = Input(shape=(df.shape[1], ))\n",
    "\n",
    "h1 = Dense(16, activation = 'relu')(encoder_inputs)\n",
    "encoded = Dense(encoded_dim, activation = 'relu')(h1)\n",
    "\n",
    "z_mean = Dense(latent_dim, name=\"z_mean\")(encoded)\n",
    "\n",
    "z_log_var = Dense(latent_dim, name=\"z_log_var\")(encoded)\n",
    "\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "latent_inputs = Input(shape=(latent_dim,))\n",
    "\n",
    "dh1 = Dense(16, activation='relu')(latent_inputs)\n",
    "\n",
    "decoder_outputs = Dense(df.shape[1], activation='sigmoid')(dh1)\n",
    "\n",
    "# this is our decoder model \n",
    "decoder = Model(inputs=latent_inputs, outputs=decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# instantiate a Variational Auto-Encoder model \n",
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "# complie the model \n",
    "vae.compile(optimizer=keras.optimizers.Nadam())\n",
    "\n",
    "stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=3, restore_best_weights=True)\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "logdir = os.path.join(\"logs\", f\"DeepVAE-{now}\")\n",
    "tensorboard = TensorBoard(log_dir=logdir)\n",
    "\n",
    "# train the model weights \n",
    "vae.fit(df, epochs=100,\n",
    "        callbacks=[stop, tensorboard])"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results deep VAE v1 (latent_dim = 16, h1 = 32): \n",
    "loss: 15.9362 - reconstruction_loss: 14.5233 - kl_loss: 1.4098\n",
    "\n",
    "**Results deep VAE v2 (latent_dim = 8, h1 = 16):**\n",
    "Epoch 21/100\n",
    "loss: 15.4746 - reconstruction_loss: 13.8923 - kl_loss: 1.6215\n",
    "\n",
    "Results regular VAE v1 (latent_dim = 16): \n",
    "loss: 15.5321 - reconstruction_loss: 13.6563 - kl_loss: 1.9151\n",
    "\n",
    "Results regular VAE v1 (latent_dim = 8):\n",
    "Epoch 12/100\n",
    "loss: 15.5430 - reconstruction_loss: 13.7091 - kl_loss: 1.8810"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Testing results\n",
    "# Encoding our songs\n",
    "z_mean, z_log_var, z = vae.encoder.predict(df)\n",
    "\n",
    "embeddings_df = pd.DataFrame(z, index=df.index)\n",
    "\n",
    "# fitting KNN\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=11, algorithm='ball_tree')\n",
    "nn.fit(z)\n",
    "\n",
    "# Testing the VAE v2\n",
    "raw_df = pd.read_csv('./Data/tracks.csv')\n",
    "\n",
    "test_songs = {'California Love': '0LyLz6XsVs6wz85dK0S6EG', 'The Gambler': '5KqldkCunQ2rWxruMEtGh0', \n",
    "              'Eye of the Tiger': '2HHtWyy5CgaQbC7XSoOb0e', 'You are my Sunshine': '4ApTr4wbyOucy2lbAvyuuV'}\n",
    "\n",
    "# Loop over all our test songs and get the recommendations\n",
    "recommendations = {}\n",
    "\n",
    "print('DeepSpot\\'s recommendation system:\\n\\n')\n",
    "\n",
    "for name, id in test_songs.items():\n",
    "    query = raw_df.index[raw_df['id'] == id][0]\n",
    "    test_song = pd.DataFrame([raw_df.iloc[query, :]])\n",
    "    \n",
    "    score, close_image_idx = nn.kneighbors(z[query].reshape(1,-1))\n",
    "    k_closest_songs_indexes = close_image_idx[0][1:]\n",
    "    \n",
    "    print('Top 10 recommendations for {} by {}:\\n'.format(name, test_song.artists))\n",
    "    for i in range(len(k_closest_songs_indexes)):\n",
    "        song = raw_df.iloc[k_closest_songs_indexes[i], :]\n",
    "        print('{} by {} with a score of {}\\n'.format(song['name'], song.artists, score[0][1:][i]))\n",
    "        print('URL: https://open.spotify.com/track/{}\\n'.format(song['id']))\n",
    "    print('___________________________________________________________________________________\\n')\n",
    "    \n",
    "    recommendations[name] = k_closest_songs_indexes\n",
    "\n",
    "embeddings_df.to_csv('./Data/vae_embeddings.csv')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "autoencoder.save('saved_model/vae_002')\n",
    "encoder.save('saved_model/encoder_002')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02e1903c3f39b96bcefa6d49f9b3f85f880bb59f74a50c875b853cacbce3839e"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('U4-S2-NN': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}